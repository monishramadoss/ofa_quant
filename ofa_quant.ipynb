{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "ofa_quant.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monishramadoss/ofa_quant/blob/main/ofa_quant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BesMFL3fVdax",
        "outputId": "d0d40e4e-40c8-46ef-d738-219006f10fc7"
      },
      "source": [
        "!pip install torch==1.8.1 torchvision==0.9.1\n",
        "!pip install ofa\n",
        "! git clone https://github.com/seshuad/IMagenet\n",
        "! ls 'IMagenet/tiny-imagenet-200/'"
      ],
      "id": "BesMFL3fVdax",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (1.8.1)\n",
            "Requirement already satisfied: torchvision==0.9.1 in /usr/local/lib/python3.7/dist-packages (0.9.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.1) (7.1.2)\n",
            "Requirement already satisfied: ofa in /usr/local/lib/python3.7/dist-packages (0.1.0.post202111231444)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from ofa) (1.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->ofa) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->ofa) (3.10.0.2)\n",
            "fatal: destination path 'IMagenet' already exists and is not an empty directory.\n",
            "test  train  val  wnids.txt  words.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp77tl4giVWJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24e7b67f-2d24-4f40-b985-6bef9fa249c2"
      },
      "source": [
        "import time\n",
        "import skimage.io as nd\n",
        "import numpy as np\n",
        "import torch\n",
        "import skimage.color\n",
        "\n",
        "\n",
        "path = 'IMagenet/tiny-imagenet-200/'\n",
        "\n",
        "def get_id_dictionary():\n",
        "    id_dict = {}\n",
        "    for i, line in enumerate(open( path + 'wnids.txt', 'r')):\n",
        "        id_dict[line.replace('\\n', '')] = i\n",
        "    return id_dict\n",
        "  \n",
        "def get_class_to_id_dict():\n",
        "    id_dict = get_id_dictionary()\n",
        "    all_classes = {}\n",
        "    result = {}\n",
        "    for i, line in enumerate(open( path + 'words.txt', 'r')):\n",
        "        n_id, word = line.split('\\t')[:2]\n",
        "        all_classes[n_id] = word\n",
        "    for key, value in id_dict.items():\n",
        "        result[value] = (key, all_classes[key])      \n",
        "    return result\n",
        "\n",
        "def get_data(id_dict):\n",
        "    print('starting loading data')\n",
        "    train_data, test_data = [], []\n",
        "    train_labels, test_labels = [], []\n",
        "    t = time.time()\n",
        "    for key, value in id_dict.items():\n",
        "        train_data += [nd.imread( path + 'train/{}/images/{}_{}.JPEG'.format(key, key, str(i)), as_gray=False ) for i in range(500)]\n",
        "        train_labels_ = np.array([[0]*200]*500)\n",
        "        train_labels_[:, value] = 1\n",
        "        train_labels += train_labels_.tolist()\n",
        "\n",
        "    for line in open( path + 'val/val_annotations.txt'):\n",
        "        img_name, class_id = line.split('\\t')[:2]\n",
        "        test_data += [nd.imread( path + 'val/images/{}'.format(img_name), as_gray=False)]\n",
        "        \n",
        "        # test_data.append(test_data_)\n",
        "        test_labels_ = np.array([[0]*200])\n",
        "        test_labels_[0, id_dict[class_id]] = 1\n",
        "        test_labels += test_labels_.tolist()\n",
        "\n",
        "    for i in range(len(test_data)):\n",
        "        if test_data[i].ndim == 2:\n",
        "            test_data[i] = skimage.color.gray2rgb(test_data[i])\n",
        "\n",
        "    for i in range(len(train_data)):\n",
        "        if train_data[i].ndim == 2:\n",
        "            train_data[i] = skimage.color.gray2rgb(train_data[i])\n",
        "\n",
        "    print('finished loading data, in {} seconds'.format(time.time() - t))\n",
        "    return np.array(train_data), np.array(train_labels), np.array(test_data), np.array(test_labels)\n",
        "\n",
        "def evaluate(model, data, target):\n",
        "    model.eval()  # set model in eval mode\n",
        "    total_time = 0\n",
        "    num_correct = 0  # total 1000\n",
        "    with torch.no_grad():\n",
        "        for image, target in zip(data, target):\n",
        "            # print(data[0].shape)\n",
        "            start = time.time()\n",
        "            result = model(image)\n",
        "            total_time += time.time() - start\n",
        "            \n",
        "            prediction = idx2label[int(result[0].sort()[1][-1:])]\n",
        "            if target == prediction:\n",
        "                num_correct += 1\n",
        "    \n",
        "    inference_time = total_time / len(data)\n",
        "    accuracy = num_correct / len(data)\n",
        "    return inference_time, accuracy\n",
        "\n",
        "train_data, train_labels, test_data, train_labels = get_data(get_id_dictionary())"
      ],
      "id": "Kp77tl4giVWJ",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting loading data\n",
            "finished loading data, in 74.54175019264221 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut9A9EV1bsDe",
        "outputId": "d10df8eb-d797-4c15-cd88-ceb6b6e43b86"
      },
      "source": [
        "print(train_data.shape, train_labels.shape)"
      ],
      "id": "ut9A9EV1bsDe",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100000, 64, 64, 3) (10000, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98SBhCpxVfeu"
      },
      "source": [
        "import copy\n",
        "import torch\n",
        "from ofa.model_zoo import ofa_net\n",
        "from ofa.imagenet_classification.data_providers.imagenet import ImagenetDataProvider\n",
        "# from ofa.imagenet_classification.run_manager import ImagenetRunConfig, RunManager\n",
        "\n",
        "raw_resnet = ofa_net('ofa_resnet50', pretrained=True)\n",
        "raw_resnet.set_max_net()\n",
        "max_subnet = raw_resnet.get_active_subnet(preserve_weight=True)\n",
        "raw_resnet.set_active_subnet(d=0, w=0, e=0)\n",
        "min_subnet = raw_resnet.get_active_subnet(preserve_weight=True)\n",
        "\n",
        "\n",
        "# ImagenetDataProvider.DEFAULT_PATH = path\n",
        "# run_config = ImagenetRunConfig(test_batch_size=16, n_worker=20)\n",
        "# run_config.data_provider.assign_active_img_size(64)\n",
        "\n",
        "\n",
        "# run_manager = RunManager('./tmp/eval_subnet', min_subnet, run_config, init=False)\n",
        "# run_manager.reset_running_statistics(net=min_subnet)"
      ],
      "id": "98SBhCpxVfeu",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X2FmwwSqbGx"
      },
      "source": [
        "# loss, (top1, top5) = run_manager.validate(net=max_subnet, is_test=True)\n",
        "# print('\\nResults: loss=%.5f,\\t top1=%.1f,\\t top5=%.1f' % (loss, top1, top5))\n",
        "# loss, (top1, top5) = run_manager.validate(net=min_subnet, is_test=True)\n",
        "# print('\\nResults: loss=%.5f,\\t top1=%.1f,\\t top5=%.1f' % (loss, top1, top5))"
      ],
      "id": "0X2FmwwSqbGx",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGw3VCBgash7"
      },
      "source": [
        "from ofa.imagenet_classification.networks import ResNets\n",
        "from ofa.utils.layers import IdentityLayer, ResidualBlock\n",
        "\n",
        "def val2list(val, repeat_time=1):\n",
        "    if isinstance(val, list) or isinstance(val, np.ndarray):\n",
        "        return val\n",
        "    elif isinstance(val, tuple):\n",
        "        return list(val)\n",
        "    else:\n",
        "        return [val for _ in range(repeat_time)]\n",
        "\n",
        "def set_active_subnet(ofa, d=None, e=None, w=None, **kwargs):\n",
        "    depth = val2list(d, len(ofa.BASE_DEPTH_LIST) + 1)\n",
        "    expand_ratio = val2list(e, len(ofa.blocks))\n",
        "    width_mult = val2list(w, len(ofa.BASE_DEPTH_LIST) + 2)\n",
        "    for block, e in zip(ofa.blocks, expand_ratio):\n",
        "        if e is not None:\n",
        "            block.active_expand_ratio = e\n",
        "\n",
        "    if width_mult[0] is not None:\n",
        "        ofa.input_stem[1].conv.active_out_channel = ofa.input_stem[0].active_out_channel = \\\n",
        "            ofa.input_stem[0].out_channel_list[width_mult[0]]\n",
        "    if width_mult[1] is not None:\n",
        "        ofa.input_stem[2].active_out_channel = ofa.input_stem[2].out_channel_list[width_mult[1]]\n",
        "\n",
        "    if depth[0] is not None:\n",
        "        ofa.input_stem_skipping = (depth[0] != max(ofa.depth_list))\n",
        "    for stage_id, (block_idx, d, w) in enumerate(zip(ofa.grouped_block_index, depth[1:], width_mult[2:])):\n",
        "        if d is not None:\n",
        "            ofa.runtime_depth[stage_id] = max(ofa.depth_list) - d\n",
        "        if w is not None:\n",
        "            for idx in block_idx:\n",
        "                ofa.blocks[idx].active_out_channel = ofa.blocks[idx].out_channel_list[w]\n",
        "\n",
        "def set_max_subnet(ofa):\n",
        "    set_active_subnet(ofa, max(ofa.depth_list), max(ofa.expand_ratio_list), len(ofa.width_mult_list) - 1)\n",
        "\n",
        "def get_active_subnet(ofa, preserve_weight=True):\n",
        "    input_stem = [ofa.input_stem[0].get_active_subnet(3, preserve_weight)]\n",
        "    active_out = ofa.input_stem[0].active_out_channel\n",
        "    input_stem_blocks = [0]\n",
        "\n",
        "    if ofa.input_stem_skipping <= 0:        \n",
        "        input_stem.append(ResidualBlock(\n",
        "            ofa.input_stem[1].conv.get_active_subnet(active_out, preserve_weight),\n",
        "            IdentityLayer(active_out, active_out)\n",
        "        ))\n",
        "        input_stem_blocks += [1]\n",
        "    input_stem_blocks += [2]\n",
        "    input_stem.append(ofa.input_stem[2].get_active_subnet(active_out, preserve_weight))\n",
        "    input_channel = ofa.input_stem[2].active_out_channel\n",
        "\n",
        "    blocks = []\n",
        "    block_groups = []\n",
        "    for stage_id, block_idx in enumerate(ofa.grouped_block_index):\n",
        "        depth_param = ofa.runtime_depth[stage_id]\n",
        "        active_idx = block_idx[:len(block_idx) - depth_param]\n",
        "        block_groups.append(active_idx)\n",
        "        for idx in active_idx:\n",
        "            blocks.append(ofa.blocks[idx].get_active_subnet(input_channel, preserve_weight))\n",
        "            input_channel = ofa.blocks[idx].active_out_channel\n",
        "    classifier = ofa.classifier.get_active_subnet(input_channel, preserve_weight)\n",
        "\n",
        "    subnet = ResNets(input_stem, blocks, classifier)\n",
        "    subnet.set_bn_param(**ofa.get_bn_param())\n",
        "    subnet.input_stem_blocks = input_stem_blocks\n",
        "    subnet.block_groups = block_groups\n",
        "    return subnet\n"
      ],
      "id": "mGw3VCBgash7",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu6ypVBm9IsY"
      },
      "source": [
        "# run_manager_quant = RunManager('./tmp/eval', min_subnet, run_config=run_config, init=False, no_gpu=True)"
      ],
      "id": "Mu6ypVBm9IsY",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjVCLHzLawE7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9c5bbe6-1354-4be4-e59b-2de7cf7678ab"
      },
      "source": [
        "input_fp32 = torch.randn(1, 3, 224, 224)\n",
        "\n",
        "set_max_subnet(raw_resnet)\n",
        "max_subnet = get_active_subnet(raw_resnet)\n",
        "\n",
        "max_subnet.eval()\n",
        "config = 'fbgemm'\n",
        "max_subnet.qconfig = torch.quantization.get_default_qconfig(config)\n",
        "max_subnet_1 = torch.quantization.prepare(max_subnet)\n",
        "_ = max_subnet_1(input_fp32)\n",
        "quat_max_model = torch.quantization.convert(max_subnet_1)\n",
        "\n",
        "\n"
      ],
      "id": "LjVCLHzLawE7",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/quantization/observer.py:123: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  reduce_range will be deprecated in a future release of PyTorch.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brYzf6rl0bii"
      },
      "source": [
        "temp = dict({('blocks.0.conv1.conv.scale', 0.3034),\n",
        " ('blocks.0.conv2.conv.scale', 0.3898),\n",
        " ('blocks.0.conv3.conv.scale', 0.3047),\n",
        " ('blocks.0.downsample.conv.scale', 0.4795),\n",
        " ('blocks.1.conv1.conv.scale', 0.2099),\n",
        " ('blocks.1.conv2.conv.scale', 0.2258),\n",
        " ('blocks.1.conv3.conv.scale', 0.3333),\n",
        " ('blocks.10.conv1.conv.scale', 0.2817),\n",
        " ('blocks.10.conv2.conv.scale', 0.3093),\n",
        " ('blocks.10.conv3.conv.scale', 0.2963),\n",
        " ('blocks.11.conv1.conv.scale', 0.6109),\n",
        " ('blocks.11.conv2.conv.scale', 0.5077),\n",
        " ('blocks.11.conv3.conv.scale', 0.3028),\n",
        " ('blocks.12.conv1.conv.scale', 0.2717),\n",
        " ('blocks.12.conv2.conv.scale', 0.2179),\n",
        " ('blocks.12.conv3.conv.scale', 0.1239),\n",
        " ('blocks.13.conv1.conv.scale', 0.2204),\n",
        " ('blocks.13.conv2.conv.scale', 0.4078),\n",
        " ('blocks.13.conv3.conv.scale', 0.3996),\n",
        " ('blocks.14.conv1.conv.scale', 0.2612),\n",
        " ('blocks.14.conv2.conv.scale', 0.2186),\n",
        " ('blocks.14.conv3.conv.scale', 0.3380),\n",
        " ('blocks.14.downsample.conv.scale', 0.5858),\n",
        " ('blocks.15.conv1.conv.scale', 0.7731),\n",
        " ('blocks.15.conv2.conv.scale', 0.4752),\n",
        " ('blocks.15.conv3.conv.scale', 0.5223),\n",
        " ('blocks.16.conv1.conv.scale', 0.3974),\n",
        " ('blocks.16.conv2.conv.scale', 0.2534),\n",
        " ('blocks.16.conv3.conv.scale', 0.3723),\n",
        " ('blocks.17.conv1.conv.scale', 0.2302),\n",
        " ('blocks.17.conv2.conv.scale', 0.2933),\n",
        " ('blocks.17.conv3.conv.scale', 0.3231),\n",
        " ('blocks.2.conv1.conv.scale', 0.1517),\n",
        " ('blocks.2.conv2.conv.scale', 0.1271),\n",
        " ('blocks.2.conv3.conv.scale', 0.1200),\n",
        " ('blocks.3.conv1.conv.scale', 0.1193),\n",
        " ('blocks.3.conv2.conv.scale', 0.1338),\n",
        " ('blocks.3.conv3.conv.scale', 0.0980),\n",
        " ('blocks.4.conv1.conv.scale', 0.2068),\n",
        " ('blocks.4.conv2.conv.scale', 0.3214),\n",
        " ('blocks.4.conv3.conv.scale', 0.4915),\n",
        " ('blocks.4.downsample.conv.scale', 0.2356),\n",
        " ('blocks.5.conv1.conv.scale', 0.1636),\n",
        " ('blocks.5.conv2.conv.scale', 0.3325),\n",
        " ('blocks.5.conv3.conv.scale', 0.3767),\n",
        " ('blocks.6.conv1.conv.scale', 0.2506),\n",
        " ('blocks.6.conv2.conv.scale', 0.2422),\n",
        " ('blocks.6.conv3.conv.scale', 0.1694),\n",
        " ('blocks.7.conv1.conv.scale', 0.2284),\n",
        " ('blocks.7.conv2.conv.scale', 0.3655),\n",
        " ('blocks.7.conv3.conv.scale', 0.3437),\n",
        " ('blocks.8.conv1.conv.scale', 0.3289),\n",
        " ('blocks.8.conv2.conv.scale', 0.3125),\n",
        " ('blocks.8.conv3.conv.scale', 0.3898),\n",
        " ('blocks.8.downsample.conv.scale', 0.5282),\n",
        " ('blocks.9.conv1.conv.scale', 0.3315),\n",
        " ('blocks.9.conv2.conv.scale', 0.3270),\n",
        " ('blocks.9.conv3.conv.scale', 0.2874),\n",
        " ('input_stem.0.conv.scale', 0.6389),\n",
        " ('input_stem.1.conv.conv.scale', 0.5264),\n",
        " ('input_stem.2.conv.scale', 0.5124)})"
      ],
      "id": "brYzf6rl0bii",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtfizHWm16D_",
        "outputId": "a3ff0746-ae01-4ab4-e0d8-e10dc916b16f"
      },
      "source": [
        "import torch.nn as nn\n",
        "def nested_children(m: torch.nn.Module):\n",
        "    children = dict(m.named_children())\n",
        "    output = {}\n",
        "    if children == {}:\n",
        "        # if module has no children; m is last child! :O\n",
        "        return m\n",
        "    else:\n",
        "        # look for children from children... to the last child!\n",
        "        for name, child in children.items():\n",
        "            try:\n",
        "                output[name] = nested_children(child)\n",
        "            except TypeError:\n",
        "                output[name] = nested_children(child)\n",
        "    return output\n",
        "\n",
        "def squash_nested_dict(nested_dict, ret_lst={}, prefix='', mod=None):\n",
        "    if nested_dict == {}:\n",
        "        ret_lst[prefix[1:]] = mod\n",
        "        return\n",
        "    for k in nested_dict.keys():\n",
        "        if isinstance(nested_dict[k], dict):\n",
        "            squash_nested_dict(nested_dict[k], ret_lst, prefix+'.'+k)\n",
        "        else:\n",
        "            squash_nested_dict({}, ret_lst, prefix+'.'+k, nested_dict[k])\n",
        "\n",
        "\n",
        "\n",
        "class Quant_Model(nn.Module):\n",
        "    def __init__(self, quat_model, float_model):\n",
        "        super(Quant_Model, self).__init__()\n",
        "        self.input_zero_points = {}\n",
        "        self.input_scales = {}\n",
        "        self.float_model = float_model\n",
        "        self.quat_model = quat_model\n",
        "        self.quant_state_dict = quat_model.state_dict()\n",
        "\n",
        "        layer_names = {}\n",
        "        named_layers = nested_children(self.float_model)\n",
        "        squash_nested_dict(named_layers, layer_names)\n",
        "        \n",
        "        for i, l in enumerate(list(layer_names.keys())):\n",
        "            layer_names[l].register_forward_pre_hook(self.forward_pre_hook(l))\n",
        "\n",
        "    def forward_pre_hook(self, layer_name):\n",
        "        def pre_hook(module, x):\n",
        "            if isinstance(module, nn.Conv2d) or isinstance(module, nn.Identity):\n",
        "                with torch.no_grad():\n",
        "                    zero_point = self.quant_state_dict[layer_name+'.zero_point'].float()\n",
        "                    scale = self.quant_state_dict[layer_name+'.scale'].float()\n",
        "                    quant_min = 0.0\n",
        "                    quant_max = 1.0\n",
        "                    tmp = torch.clamp(torch.round(torch.div(x[0], scale) + zero_point), quant_min, quant_max) - zero_point\n",
        "                    x = tmp*scale\n",
        "            return x\n",
        "        return pre_hook\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.float_model(x)\n",
        "\n",
        "\n",
        "set_active_subnet(raw_resnet, 0, 0, 0)\n",
        "min_subnet = get_active_subnet(raw_resnet)\n",
        "min_subnet.eval()\n",
        "min_subnet.qconfig = torch.quantization.get_default_qconfig(config)\n",
        "\n",
        "input_fp32 = torch.randn(1, 3, 224, 224, dtype=torch.float32)\n",
        "min_subnet_1 = torch.quantization.prepare(min_subnet)\n",
        "\n",
        "_ = min_subnet_1(input_fp32)\n",
        "quat_min_model = torch.quantization.convert(min_subnet_1)\n",
        "\n",
        "fake_quant_model = Quant_Model(quat_min_model, min_subnet)\n",
        "fake_output = fake_quant_model(input_fp32)\n",
        "print(fake_output)"
      ],
      "id": "FtfizHWm16D_",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/quantization/observer.py:123: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  reduce_range will be deprecated in a future release of PyTorch.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-294.3520,   -6.4059,  -54.2019,  -22.4575,  226.8641, -114.8154,\n",
            "           48.1599,   56.9619,  178.0162,   37.6929,  -44.8707,  -82.7839,\n",
            "           27.2446,   58.1014,  -16.6967,  -73.0909,  -38.6167,  -41.2054,\n",
            "          -20.8798,  -46.9885, -116.7103,   21.6681, -210.4739,   35.4657,\n",
            "           66.3895,  -70.4779,  -60.9834,  -41.7618,  -22.8354, -103.7682,\n",
            "          194.7356,  -97.0490,   54.3800,  -55.0787,  -59.3974,   60.3609,\n",
            "          131.6946,   79.7695, -164.7478,  114.2307,  -51.0119,   62.6533,\n",
            "           56.7777,  141.8246,   72.9990,   -6.5813,  -47.0276,   84.5642,\n",
            "           99.7476,  -23.6089,  114.4185,   18.6132, -103.0928,  -54.2114,\n",
            "            1.4460, -149.8541, -155.3235,   81.7572,   33.7372,  -67.0638,\n",
            "          -82.4987, -126.4726,  121.7566,   75.9322,  -99.2471,   99.3848,\n",
            "         -124.1902,   -3.2048, -179.7852, -100.1188,  -33.5885,   -0.4123,\n",
            "         -126.8417,  -46.3178,   -7.1046,  -75.6903,  -18.5515,   28.3253,\n",
            "           -8.9110,  -30.0375,   44.3419,   35.6532,   50.6179,  -40.6564,\n",
            "          152.6737,   51.9800,   63.6378, -201.4392,  -76.1195, -106.0650,\n",
            "           -2.7331, -120.0507,   70.3972,  -90.8524,  -17.3267, -163.2505,\n",
            "         -148.1424,   12.2735,   57.5671,   38.0445,  -47.3400,   49.9757,\n",
            "           61.9077, -130.6180,  170.2247,  -73.9727,   42.6110,  -11.9728,\n",
            "          -80.5863,   29.7173,  -61.9776,  -57.3345,   95.6367,  104.5937,\n",
            "           39.7984,  -76.7595,   24.5439, -113.7419,   26.1186,  117.0210,\n",
            "          169.6200,   50.7200, -139.2797,   15.9951,  213.2316,   52.5009,\n",
            "           -6.3657,  -95.9494,  -33.0947, -135.0428, -135.8181, -183.8058,\n",
            "         -203.6617,   67.4731,   -6.3722,  -18.3327,   26.9375,   72.4017,\n",
            "          -11.9204,  -34.4830,  -28.5477,   67.6931,   33.5983,  -15.1381,\n",
            "            4.7174,  -91.6670,   23.3216,  -67.1808,  -17.1872, -197.4350,\n",
            "           73.7585,   59.5329, -104.5268,  -96.4920,   17.3326,   64.9113,\n",
            "          -86.0190, -113.1814, -105.2841,   32.6228,   32.5494,    2.0933,\n",
            "         -223.8740,  -10.1162,   93.3241,  -15.2827, -114.8751,  -60.2604,\n",
            "          157.0285,  -79.6101,  -11.7777,  -59.4377,  -58.7959,  -80.3467,\n",
            "           16.2924,  -67.4368,  148.6678,  -53.4769,   90.7791,    1.4010,\n",
            "          -53.0120,  -72.1154,  -30.8263,    0.6536, -112.8758,   66.5876,\n",
            "          -58.3578,   28.6873, -141.6914, -203.7631, -244.1308,  -68.8357,\n",
            "           61.6999,  -28.5654,  -56.9432,  -64.2479,  114.3293,  -11.0408,\n",
            "           10.5594,   -9.0436, -150.6960,  -33.0112,   90.7684,  -84.5981,\n",
            "           36.9805,   97.1406,  -35.0689, -116.3249,  -99.8461,   20.1957,\n",
            "           10.1788,  -51.5829,   30.5225,  -43.3116,   -6.5383,  -56.4718,\n",
            "           26.3450,  -60.4130, -106.0609,   72.7368, -111.6213,  -99.6603,\n",
            "           67.8796,   45.8722,   18.9286,  -42.2807,  -88.6467,  -81.7640,\n",
            "          -33.8304,   58.8994, -104.4330,    6.1141,   -8.1109, -104.3650,\n",
            "         -143.7380,  -46.6212,   35.6559,   30.8120,  -11.0489,  -52.5555,\n",
            "          -75.4542, -113.7010,   65.6977, -107.7952,   98.9500,   18.6925,\n",
            "          -13.6261,   22.8396,  -43.2892,  -16.6362,  -76.3062,  -49.4007,\n",
            "          -94.6469,  -90.3620,   20.9735,  -11.1376,   89.4198,  -16.7860,\n",
            "         -112.1597,   17.0787,   19.2479,  -35.9550,  100.2285,  -94.1729,\n",
            "           65.0766,   48.7668,   50.9711,   51.5299,  129.4508,  -41.6052,\n",
            "         -167.7481,  -10.3409,   -3.8223,  -37.4950,  107.1011, -129.3913,\n",
            "         -187.2728,  -40.8161, -216.9919, -122.0380,  -19.0343,  -18.5057,\n",
            "           78.0273,  -47.1603,  -14.3714,    2.9355,   50.5588,   84.0914,\n",
            "          -16.7658,  -89.8703,  -10.3309,   80.0701,   30.9689,  -23.1797,\n",
            "           -9.3232,   99.8127, -134.9176,   64.3819,  -25.2103,   35.0903,\n",
            "          -49.7090,   21.0051,  -40.5840,   16.9747,  -70.5838,   45.5894,\n",
            "          -45.8798,   71.8988,   -7.4999,  -93.0601,  160.4088,   -2.0493,\n",
            "          101.4197,  -15.0783,   -7.4840,   59.3816,  -41.3624,  -10.6876,\n",
            "         -185.4651,  -68.9643,   11.2083,  -24.7818,  -15.5704,  -94.6153,\n",
            "         -103.3195,  -70.9393, -119.7169,  146.8088,  103.9137,   15.5729,\n",
            "          216.5861,   67.5503,   89.4313, -164.2928,  122.0875,   16.7398,\n",
            "           15.2474,   -3.7585, -122.3934,  -33.8647,   -8.0015,   44.8753,\n",
            "           63.1817,   63.0828,  -24.3490,  153.2869,  107.9269,  -48.9475,\n",
            "          202.7774,  167.8510,  198.1338,  -52.9126,   26.8191,  107.8376,\n",
            "          170.6198,  195.6731,  -28.6298,  -10.5330,   58.8807, -189.0374,\n",
            "           11.8585,  -65.9337,  -61.3358,  -44.0031,   36.9461,   30.8921,\n",
            "           87.0356,  112.1554,   71.2374,    2.6904, -133.9291,  -59.4080,\n",
            "            7.3767,   20.6921,   -5.5372,  -13.1813,  -46.8576,  -25.9240,\n",
            "          -88.7652, -104.5892, -117.0970,   39.6852,  -35.6270,  -47.2171,\n",
            "           14.0770,   84.7635,  -50.4555,  -84.8906, -100.4171, -199.7375,\n",
            "          101.9691,    3.9379, -126.3793, -201.7368, -180.3344, -108.8692,\n",
            "          -69.3543,  -31.7017,   41.5332,  -28.1751,  -62.8399,  141.7278,\n",
            "           24.5506,  -26.6660,  -25.1287,   15.7922, -113.6982,  -67.7717,\n",
            "           52.9387,  -12.1042,    1.4127,  118.1425,  165.7337,  -55.9023,\n",
            "          254.0775,   55.7109,  -89.1334,    2.7660,  -58.7235,   31.8174,\n",
            "           84.2204,  143.3052, -192.5979, -227.7486, -213.6076,  153.8753,\n",
            "            7.7799,  179.2021,  127.4109, -173.3181, -317.8329,  -40.6275,\n",
            "           18.5888, -182.2602, -135.2224,   56.9696, -101.8661,  123.4093,\n",
            "          -71.2871,  -84.8428,  -43.0292, -147.9619,   58.9176,  -75.3055,\n",
            "         -206.9149, -217.1022,  137.8513,  106.3742,   -1.7461,   39.2596,\n",
            "          -24.8627,  161.9402,   67.6564,  116.4165,   53.5301, -219.9751,\n",
            "          -55.5175,  201.1109,  261.1229, -159.8263,  219.5535,  -21.8242,\n",
            "          150.4218,  207.5606,   94.9179,   -2.3357,   -9.4159, -146.6370,\n",
            "          -73.3423,   61.1051,   38.7653,   23.7049,   24.8955,  -73.8612,\n",
            "            7.0488, -202.4136,  -66.9684,  108.1521,  294.3346,   -0.5982,\n",
            "           84.7197,   65.5869,  244.0159,   63.6724, -161.7161,   44.4568,\n",
            "         -147.4532,    7.2193,  116.2425,  271.9961, -107.1965, -133.3436,\n",
            "          187.7403,   24.3607, -116.5701,   -5.5689,  -59.3261,  151.0296,\n",
            "          -16.1053,   -1.6974,   44.5416,   23.7236,   43.7033,  -31.0607,\n",
            "         -133.3891,   45.4188,  -63.4102,   -3.3158,   71.1888,  244.2184,\n",
            "          -56.9135,  -93.7581,   -0.3815,  -48.0551,  167.1344,  272.2844,\n",
            "           95.6164,  211.7383,  200.8727,  156.1058,  -63.5340,  145.6887,\n",
            "          -80.5603,  153.2518,  -50.4885,   18.8557,  198.3169,  184.5369,\n",
            "           33.1274,   42.3062,   44.6956,  -51.7098,  104.0664,  -27.7285,\n",
            "          154.7999,   24.3294, -102.3090, -122.5526,   42.7841,  126.3147,\n",
            "           54.0190,  -28.8299,  -19.3135,  -60.1952,   98.2615,  194.2117,\n",
            "           -3.4861,  -24.0970, -132.8330,   38.9212,  -55.2215, -102.5300,\n",
            "           28.5166,  115.0831,   58.4259,   60.2914,  -22.0278,  -33.3537,\n",
            "           59.5645,  -83.8794, -122.4715,   13.3696,  123.8781,  -25.5270,\n",
            "          -34.8905,  -66.5767,   78.2449,   73.9592,  157.2837,  154.8080,\n",
            "           -8.9392,  163.5809,   23.9491,  -40.4677, -159.2210,   28.2421,\n",
            "           59.5676, -107.0769, -168.0080,   93.5789,  120.8688, -157.9208,\n",
            "          -32.7727,  133.9761, -149.1080,   -6.3867,  -32.6924,  107.2362,\n",
            "           81.8809,  142.6382, -119.8771,   64.6173,   67.9501,   23.0724,\n",
            "          227.4032,  -44.5283,    6.0507,  152.0255,  -78.7059,  121.4443,\n",
            "         -143.8066, -127.9080,  -48.0331,   98.7025,  -10.0885,  100.3233,\n",
            "           -2.5150, -160.5963,  151.1330,   64.5345,   51.1639,  -51.4190,\n",
            "           22.2387,   10.3160, -216.1681,   14.8078,   70.3314,   65.1732,\n",
            "          118.7277,  156.3720,  143.9208,    4.7588,  -14.6366,  -68.1251,\n",
            "          218.2525, -117.8528,  144.6257,  -76.9758,   16.1108, -117.0894,\n",
            "          111.6600,  -12.8031,   45.9142,  131.3475,   85.7921,   45.1714,\n",
            "          158.8299,  160.8924, -226.6824, -123.1494,   75.5563, -209.7385,\n",
            "           -3.8108,   60.4197, -145.2690,  -49.9954,   35.9627, -138.2180,\n",
            "         -197.3572,  -53.0553,   95.3711,   41.2456,   90.7068,  184.7119,\n",
            "           91.2848,  118.1545, -115.3254,   16.5367,  -61.7273,  -90.8569,\n",
            "          -81.7404,   69.3600,   43.7086,   -1.8043,   51.3588,  -31.7729,\n",
            "          182.7089, -145.5463,   44.9167,  -36.6722,  -36.5870, -159.2577,\n",
            "           98.2489,  110.1273,   16.6464,  -12.9272,  -24.9794,  -71.4823,\n",
            "          114.3188,  -19.0316, -208.5315,  169.4610,   47.2354,  -71.7464,\n",
            "          101.9791,  -54.8036,  -13.7262,  -86.0696,   26.0975, -126.3938,\n",
            "          165.5436,  107.5683,   36.5158,  -67.8290, -136.4399,  -70.9342,\n",
            "          -61.0368,  -91.9552,  -35.4938, -115.5572,   92.6709,  -27.5280,\n",
            "          -57.2204,  179.0304,   89.7504,  -10.1235,  -40.2112,  256.9755,\n",
            "          226.0410, -138.6568,  -84.6157,   47.0584,   34.9158,  127.5176,\n",
            "          -39.0034, -131.7882,  -40.9361,  -73.7458,  178.5033, -136.5314,\n",
            "           42.3806,  -11.4186, -147.0510, -201.6824,   88.7158,  -48.4079,\n",
            "          -96.7001,  101.9796,  154.2159,   45.9535,  -20.2926,   55.0061,\n",
            "           26.2589,  185.8791, -169.3950,  163.2763,  -89.1698,  -59.0417,\n",
            "           72.1558,  -44.5411,    6.5436,    1.4930,   31.1105,  -92.0221,\n",
            "           -4.1147,    2.4115,   -5.1096,  -47.0818,   76.7019,  147.9066,\n",
            "          -15.6483,  -55.4071,  -58.2162,  111.9902,   14.8393,  -20.7892,\n",
            "          107.2204,  -53.4780,   25.9071,  -30.2657,  137.4992,  191.4633,\n",
            "          -25.3403,  -65.3647,  136.9301,  -51.4413,   75.7415,  -13.4386,\n",
            "         -106.2685,  -77.3495,   57.5038,   88.6288, -117.0650, -237.3421,\n",
            "          126.2460,   48.5527,   62.4305,  -49.5134,  176.3624, -122.1484,\n",
            "          140.6672,  -74.9613,   90.3387,   64.0813,   75.9146,  113.8239,\n",
            "          -26.2303,  -90.8222,  105.4086,  -50.1595,   53.3272,  166.3869,\n",
            "           61.3779,  -83.6620,    6.1801, -130.4757,   99.0161,   42.7472,\n",
            "           74.9737,   41.9576,   64.2126, -308.4356, -125.4311,  -71.7259,\n",
            "          -29.3816,   50.0663,  -66.9169,  199.4800,  -34.4639,  -34.9681,\n",
            "          191.4438,  330.2423, -128.0978,  138.0988,  -70.8613,   43.2943,\n",
            "         -117.8722,  -67.5361,  157.6713,  -34.8769,   15.8480,  208.5752,\n",
            "          -87.2893,   59.4954,  120.0052,   88.9014,   53.0877,   84.8465,\n",
            "          -70.2423,   58.4338,  -56.7007,   84.9695,   36.7732,   18.3880,\n",
            "          173.9402,   36.3335,  -35.0102,   56.5232, -140.8276,   53.5489,\n",
            "          293.9240,  221.9151, -108.7619, -169.1267,   84.1492,    5.7310,\n",
            "           54.8273,  -95.5827,  171.5713,    2.7031,   25.4753,  299.7874,\n",
            "           40.5829,  252.1469,   21.4556,  -95.3106,   28.8778,  -70.1404,\n",
            "          121.6553,   80.3877,  103.1388,  156.4871,  -52.4100,   31.7192,\n",
            "           23.5900,  -76.5471,   91.2104, -145.0511,  275.7755,  -59.6405,\n",
            "           -7.2767,  -79.1944,  274.2896,   17.4351,  -52.4464,  -92.5419,\n",
            "           20.8780,  125.4869,  155.6601,  -58.2098,  -20.6389,  162.1687,\n",
            "           70.4679,  188.6799,  109.3767,   47.1902,   34.4837,  -99.4626,\n",
            "           15.8372,  -42.7143,  -67.9953,  -32.0358,  111.5791,  -50.0017,\n",
            "           81.0101, -144.7388,   10.2660,  177.4949,   89.2598,  145.1711,\n",
            "           51.4586, -120.6275,   69.8386,  -66.1725, -116.4692,  -99.3948,\n",
            "          124.2308,   11.0884,   43.0947,   -9.5382,  -17.2911,   31.4673,\n",
            "          -54.5043,  -80.7622,   -4.0642,  215.8349, -127.1838,  -98.7894,\n",
            "           -3.0993,  117.7282,   75.6236,  -88.8041,   -7.8283,  -18.6562,\n",
            "           33.6855,  -45.3770, -116.5928,  -55.4999,  -76.0334,   60.0412,\n",
            "          -79.9894,  -61.3660,  -92.5335,   79.7375,   80.3112,  -50.3780,\n",
            "           22.2076,  -36.3265,   -9.5114, -214.4438,   25.4060,    3.5165,\n",
            "         -135.2233,  -49.4344,  -19.0399,  -80.7537,  -10.1323,  -30.0528,\n",
            "          -55.0841,  -36.5105,   82.9091,  -65.5551,   72.2230,   -1.1935,\n",
            "           57.7840,    8.0982,    3.6153, -126.4919,  -72.4487, -188.3412,\n",
            "         -212.1779,  -66.2685,  -10.1536,  -37.0502,  -61.0466,   -5.5166,\n",
            "          -76.2995,  -64.1618,   59.3941,  -36.6015,  -35.0082,  -76.4990,\n",
            "           96.8776,  -74.8873, -175.8267,  127.3961, -175.0054,   98.3313,\n",
            "          -89.6793,  -29.7471, -110.9487, -202.7113,  -53.6595,  -47.3965,\n",
            "         -155.4797,   46.0795, -161.8684,  -26.0090,   26.9249, -104.4004,\n",
            "          -21.7861,   94.9321,  -93.8422,  -64.8610,  -69.3709,   14.2348,\n",
            "          -45.0070,  -35.0688,   47.9899,   86.0436]], grad_fn=<AddmmBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOLbEMvy_L_O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4cb8c18b-3eb3-4296-9396-175daf057801"
      },
      "source": [
        "open(\"./tmp\",\"w\")\n",
        "set_max_subnet(raw_resnet)\n",
        "\n",
        "max_subnet = get_active_subnet(raw_resnet)\n",
        "\n",
        "st_dict = torch.load('./weight_after_ps.pth')\n",
        "print(st_dict.keys())\n",
        "# max_subnet.load_state_dict(st_dict)\n",
        "# max_subnet_1 = torch.quantization.prepare(max_subnet)\n",
        "\n",
        "_ = max_subnet_1(input_fp32)\n",
        "quat_max_model = torch.quantization.convert(max_subnet_1)\n",
        "\n",
        "fake_quant_model = Quant_Model(quat_max_model, max_subnet)\n",
        "fake_output = fake_quant_model(input_fp32)\n",
        "print(fake_output)"
      ],
      "id": "SOLbEMvy_L_O",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['input_stem.0.conv.weight', 'input_stem.0.bn.weight', 'input_stem.0.bn.bias', 'input_stem.0.bn.running_mean', 'input_stem.0.bn.running_var', 'input_stem.0.bn.num_batches_tracked', 'input_stem.1.conv.conv.weight', 'input_stem.1.conv.bn.weight', 'input_stem.1.conv.bn.bias', 'input_stem.1.conv.bn.running_mean', 'input_stem.1.conv.bn.running_var', 'input_stem.1.conv.bn.num_batches_tracked', 'input_stem.2.conv.weight', 'input_stem.2.bn.weight', 'input_stem.2.bn.bias', 'input_stem.2.bn.running_mean', 'input_stem.2.bn.running_var', 'input_stem.2.bn.num_batches_tracked', 'blocks.0.conv1.conv.weight', 'blocks.0.conv1.bn.weight', 'blocks.0.conv1.bn.bias', 'blocks.0.conv1.bn.running_mean', 'blocks.0.conv1.bn.running_var', 'blocks.0.conv1.bn.num_batches_tracked', 'blocks.0.conv2.conv.weight', 'blocks.0.conv2.bn.weight', 'blocks.0.conv2.bn.bias', 'blocks.0.conv2.bn.running_mean', 'blocks.0.conv2.bn.running_var', 'blocks.0.conv2.bn.num_batches_tracked', 'blocks.0.conv3.conv.weight', 'blocks.0.conv3.bn.weight', 'blocks.0.conv3.bn.bias', 'blocks.0.conv3.bn.running_mean', 'blocks.0.conv3.bn.running_var', 'blocks.0.conv3.bn.num_batches_tracked', 'blocks.0.downsample.conv.weight', 'blocks.0.downsample.bn.weight', 'blocks.0.downsample.bn.bias', 'blocks.0.downsample.bn.running_mean', 'blocks.0.downsample.bn.running_var', 'blocks.0.downsample.bn.num_batches_tracked', 'blocks.1.conv1.conv.weight', 'blocks.1.conv1.bn.weight', 'blocks.1.conv1.bn.bias', 'blocks.1.conv1.bn.running_mean', 'blocks.1.conv1.bn.running_var', 'blocks.1.conv1.bn.num_batches_tracked', 'blocks.1.conv2.conv.weight', 'blocks.1.conv2.bn.weight', 'blocks.1.conv2.bn.bias', 'blocks.1.conv2.bn.running_mean', 'blocks.1.conv2.bn.running_var', 'blocks.1.conv2.bn.num_batches_tracked', 'blocks.1.conv3.conv.weight', 'blocks.1.conv3.bn.weight', 'blocks.1.conv3.bn.bias', 'blocks.1.conv3.bn.running_mean', 'blocks.1.conv3.bn.running_var', 'blocks.1.conv3.bn.num_batches_tracked', 'blocks.2.conv1.conv.weight', 'blocks.2.conv1.bn.weight', 'blocks.2.conv1.bn.bias', 'blocks.2.conv1.bn.running_mean', 'blocks.2.conv1.bn.running_var', 'blocks.2.conv1.bn.num_batches_tracked', 'blocks.2.conv2.conv.weight', 'blocks.2.conv2.bn.weight', 'blocks.2.conv2.bn.bias', 'blocks.2.conv2.bn.running_mean', 'blocks.2.conv2.bn.running_var', 'blocks.2.conv2.bn.num_batches_tracked', 'blocks.2.conv3.conv.weight', 'blocks.2.conv3.bn.weight', 'blocks.2.conv3.bn.bias', 'blocks.2.conv3.bn.running_mean', 'blocks.2.conv3.bn.running_var', 'blocks.2.conv3.bn.num_batches_tracked', 'blocks.3.conv1.conv.weight', 'blocks.3.conv1.bn.weight', 'blocks.3.conv1.bn.bias', 'blocks.3.conv1.bn.running_mean', 'blocks.3.conv1.bn.running_var', 'blocks.3.conv1.bn.num_batches_tracked', 'blocks.3.conv2.conv.weight', 'blocks.3.conv2.bn.weight', 'blocks.3.conv2.bn.bias', 'blocks.3.conv2.bn.running_mean', 'blocks.3.conv2.bn.running_var', 'blocks.3.conv2.bn.num_batches_tracked', 'blocks.3.conv3.conv.weight', 'blocks.3.conv3.bn.weight', 'blocks.3.conv3.bn.bias', 'blocks.3.conv3.bn.running_mean', 'blocks.3.conv3.bn.running_var', 'blocks.3.conv3.bn.num_batches_tracked', 'blocks.4.conv1.conv.weight', 'blocks.4.conv1.bn.weight', 'blocks.4.conv1.bn.bias', 'blocks.4.conv1.bn.running_mean', 'blocks.4.conv1.bn.running_var', 'blocks.4.conv1.bn.num_batches_tracked', 'blocks.4.conv2.conv.weight', 'blocks.4.conv2.bn.weight', 'blocks.4.conv2.bn.bias', 'blocks.4.conv2.bn.running_mean', 'blocks.4.conv2.bn.running_var', 'blocks.4.conv2.bn.num_batches_tracked', 'blocks.4.conv3.conv.weight', 'blocks.4.conv3.bn.weight', 'blocks.4.conv3.bn.bias', 'blocks.4.conv3.bn.running_mean', 'blocks.4.conv3.bn.running_var', 'blocks.4.conv3.bn.num_batches_tracked', 'blocks.4.downsample.conv.weight', 'blocks.4.downsample.bn.weight', 'blocks.4.downsample.bn.bias', 'blocks.4.downsample.bn.running_mean', 'blocks.4.downsample.bn.running_var', 'blocks.4.downsample.bn.num_batches_tracked', 'blocks.5.conv1.conv.weight', 'blocks.5.conv1.bn.weight', 'blocks.5.conv1.bn.bias', 'blocks.5.conv1.bn.running_mean', 'blocks.5.conv1.bn.running_var', 'blocks.5.conv1.bn.num_batches_tracked', 'blocks.5.conv2.conv.weight', 'blocks.5.conv2.bn.weight', 'blocks.5.conv2.bn.bias', 'blocks.5.conv2.bn.running_mean', 'blocks.5.conv2.bn.running_var', 'blocks.5.conv2.bn.num_batches_tracked', 'blocks.5.conv3.conv.weight', 'blocks.5.conv3.bn.weight', 'blocks.5.conv3.bn.bias', 'blocks.5.conv3.bn.running_mean', 'blocks.5.conv3.bn.running_var', 'blocks.5.conv3.bn.num_batches_tracked', 'blocks.6.conv1.conv.weight', 'blocks.6.conv1.bn.weight', 'blocks.6.conv1.bn.bias', 'blocks.6.conv1.bn.running_mean', 'blocks.6.conv1.bn.running_var', 'blocks.6.conv1.bn.num_batches_tracked', 'blocks.6.conv2.conv.weight', 'blocks.6.conv2.bn.weight', 'blocks.6.conv2.bn.bias', 'blocks.6.conv2.bn.running_mean', 'blocks.6.conv2.bn.running_var', 'blocks.6.conv2.bn.num_batches_tracked', 'blocks.6.conv3.conv.weight', 'blocks.6.conv3.bn.weight', 'blocks.6.conv3.bn.bias', 'blocks.6.conv3.bn.running_mean', 'blocks.6.conv3.bn.running_var', 'blocks.6.conv3.bn.num_batches_tracked', 'blocks.7.conv1.conv.weight', 'blocks.7.conv1.bn.weight', 'blocks.7.conv1.bn.bias', 'blocks.7.conv1.bn.running_mean', 'blocks.7.conv1.bn.running_var', 'blocks.7.conv1.bn.num_batches_tracked', 'blocks.7.conv2.conv.weight', 'blocks.7.conv2.bn.weight', 'blocks.7.conv2.bn.bias', 'blocks.7.conv2.bn.running_mean', 'blocks.7.conv2.bn.running_var', 'blocks.7.conv2.bn.num_batches_tracked', 'blocks.7.conv3.conv.weight', 'blocks.7.conv3.bn.weight', 'blocks.7.conv3.bn.bias', 'blocks.7.conv3.bn.running_mean', 'blocks.7.conv3.bn.running_var', 'blocks.7.conv3.bn.num_batches_tracked', 'blocks.8.conv1.conv.weight', 'blocks.8.conv1.bn.weight', 'blocks.8.conv1.bn.bias', 'blocks.8.conv1.bn.running_mean', 'blocks.8.conv1.bn.running_var', 'blocks.8.conv1.bn.num_batches_tracked', 'blocks.8.conv2.conv.weight', 'blocks.8.conv2.bn.weight', 'blocks.8.conv2.bn.bias', 'blocks.8.conv2.bn.running_mean', 'blocks.8.conv2.bn.running_var', 'blocks.8.conv2.bn.num_batches_tracked', 'blocks.8.conv3.conv.weight', 'blocks.8.conv3.bn.weight', 'blocks.8.conv3.bn.bias', 'blocks.8.conv3.bn.running_mean', 'blocks.8.conv3.bn.running_var', 'blocks.8.conv3.bn.num_batches_tracked', 'blocks.8.downsample.conv.weight', 'blocks.8.downsample.bn.weight', 'blocks.8.downsample.bn.bias', 'blocks.8.downsample.bn.running_mean', 'blocks.8.downsample.bn.running_var', 'blocks.8.downsample.bn.num_batches_tracked', 'blocks.9.conv1.conv.weight', 'blocks.9.conv1.bn.weight', 'blocks.9.conv1.bn.bias', 'blocks.9.conv1.bn.running_mean', 'blocks.9.conv1.bn.running_var', 'blocks.9.conv1.bn.num_batches_tracked', 'blocks.9.conv2.conv.weight', 'blocks.9.conv2.bn.weight', 'blocks.9.conv2.bn.bias', 'blocks.9.conv2.bn.running_mean', 'blocks.9.conv2.bn.running_var', 'blocks.9.conv2.bn.num_batches_tracked', 'blocks.9.conv3.conv.weight', 'blocks.9.conv3.bn.weight', 'blocks.9.conv3.bn.bias', 'blocks.9.conv3.bn.running_mean', 'blocks.9.conv3.bn.running_var', 'blocks.9.conv3.bn.num_batches_tracked', 'blocks.10.conv1.conv.weight', 'blocks.10.conv1.bn.weight', 'blocks.10.conv1.bn.bias', 'blocks.10.conv1.bn.running_mean', 'blocks.10.conv1.bn.running_var', 'blocks.10.conv1.bn.num_batches_tracked', 'blocks.10.conv2.conv.weight', 'blocks.10.conv2.bn.weight', 'blocks.10.conv2.bn.bias', 'blocks.10.conv2.bn.running_mean', 'blocks.10.conv2.bn.running_var', 'blocks.10.conv2.bn.num_batches_tracked', 'blocks.10.conv3.conv.weight', 'blocks.10.conv3.bn.weight', 'blocks.10.conv3.bn.bias', 'blocks.10.conv3.bn.running_mean', 'blocks.10.conv3.bn.running_var', 'blocks.10.conv3.bn.num_batches_tracked', 'blocks.11.conv1.conv.weight', 'blocks.11.conv1.bn.weight', 'blocks.11.conv1.bn.bias', 'blocks.11.conv1.bn.running_mean', 'blocks.11.conv1.bn.running_var', 'blocks.11.conv1.bn.num_batches_tracked', 'blocks.11.conv2.conv.weight', 'blocks.11.conv2.bn.weight', 'blocks.11.conv2.bn.bias', 'blocks.11.conv2.bn.running_mean', 'blocks.11.conv2.bn.running_var', 'blocks.11.conv2.bn.num_batches_tracked', 'blocks.11.conv3.conv.weight', 'blocks.11.conv3.bn.weight', 'blocks.11.conv3.bn.bias', 'blocks.11.conv3.bn.running_mean', 'blocks.11.conv3.bn.running_var', 'blocks.11.conv3.bn.num_batches_tracked', 'blocks.12.conv1.conv.weight', 'blocks.12.conv1.bn.weight', 'blocks.12.conv1.bn.bias', 'blocks.12.conv1.bn.running_mean', 'blocks.12.conv1.bn.running_var', 'blocks.12.conv1.bn.num_batches_tracked', 'blocks.12.conv2.conv.weight', 'blocks.12.conv2.bn.weight', 'blocks.12.conv2.bn.bias', 'blocks.12.conv2.bn.running_mean', 'blocks.12.conv2.bn.running_var', 'blocks.12.conv2.bn.num_batches_tracked', 'blocks.12.conv3.conv.weight', 'blocks.12.conv3.bn.weight', 'blocks.12.conv3.bn.bias', 'blocks.12.conv3.bn.running_mean', 'blocks.12.conv3.bn.running_var', 'blocks.12.conv3.bn.num_batches_tracked', 'blocks.13.conv1.conv.weight', 'blocks.13.conv1.bn.weight', 'blocks.13.conv1.bn.bias', 'blocks.13.conv1.bn.running_mean', 'blocks.13.conv1.bn.running_var', 'blocks.13.conv1.bn.num_batches_tracked', 'blocks.13.conv2.conv.weight', 'blocks.13.conv2.bn.weight', 'blocks.13.conv2.bn.bias', 'blocks.13.conv2.bn.running_mean', 'blocks.13.conv2.bn.running_var', 'blocks.13.conv2.bn.num_batches_tracked', 'blocks.13.conv3.conv.weight', 'blocks.13.conv3.bn.weight', 'blocks.13.conv3.bn.bias', 'blocks.13.conv3.bn.running_mean', 'blocks.13.conv3.bn.running_var', 'blocks.13.conv3.bn.num_batches_tracked', 'blocks.14.conv1.conv.weight', 'blocks.14.conv1.bn.weight', 'blocks.14.conv1.bn.bias', 'blocks.14.conv1.bn.running_mean', 'blocks.14.conv1.bn.running_var', 'blocks.14.conv1.bn.num_batches_tracked', 'blocks.14.conv2.conv.weight', 'blocks.14.conv2.bn.weight', 'blocks.14.conv2.bn.bias', 'blocks.14.conv2.bn.running_mean', 'blocks.14.conv2.bn.running_var', 'blocks.14.conv2.bn.num_batches_tracked', 'blocks.14.conv3.conv.weight', 'blocks.14.conv3.bn.weight', 'blocks.14.conv3.bn.bias', 'blocks.14.conv3.bn.running_mean', 'blocks.14.conv3.bn.running_var', 'blocks.14.conv3.bn.num_batches_tracked', 'blocks.14.downsample.conv.weight', 'blocks.14.downsample.bn.weight', 'blocks.14.downsample.bn.bias', 'blocks.14.downsample.bn.running_mean', 'blocks.14.downsample.bn.running_var', 'blocks.14.downsample.bn.num_batches_tracked', 'blocks.15.conv1.conv.weight', 'blocks.15.conv1.bn.weight', 'blocks.15.conv1.bn.bias', 'blocks.15.conv1.bn.running_mean', 'blocks.15.conv1.bn.running_var', 'blocks.15.conv1.bn.num_batches_tracked', 'blocks.15.conv2.conv.weight', 'blocks.15.conv2.bn.weight', 'blocks.15.conv2.bn.bias', 'blocks.15.conv2.bn.running_mean', 'blocks.15.conv2.bn.running_var', 'blocks.15.conv2.bn.num_batches_tracked', 'blocks.15.conv3.conv.weight', 'blocks.15.conv3.bn.weight', 'blocks.15.conv3.bn.bias', 'blocks.15.conv3.bn.running_mean', 'blocks.15.conv3.bn.running_var', 'blocks.15.conv3.bn.num_batches_tracked', 'blocks.16.conv1.conv.weight', 'blocks.16.conv1.bn.weight', 'blocks.16.conv1.bn.bias', 'blocks.16.conv1.bn.running_mean', 'blocks.16.conv1.bn.running_var', 'blocks.16.conv1.bn.num_batches_tracked', 'blocks.16.conv2.conv.weight', 'blocks.16.conv2.bn.weight', 'blocks.16.conv2.bn.bias', 'blocks.16.conv2.bn.running_mean', 'blocks.16.conv2.bn.running_var', 'blocks.16.conv2.bn.num_batches_tracked', 'blocks.16.conv3.conv.weight', 'blocks.16.conv3.bn.weight', 'blocks.16.conv3.bn.bias', 'blocks.16.conv3.bn.running_mean', 'blocks.16.conv3.bn.running_var', 'blocks.16.conv3.bn.num_batches_tracked', 'blocks.17.conv1.conv.weight', 'blocks.17.conv1.bn.weight', 'blocks.17.conv1.bn.bias', 'blocks.17.conv1.bn.running_mean', 'blocks.17.conv1.bn.running_var', 'blocks.17.conv1.bn.num_batches_tracked', 'blocks.17.conv2.conv.weight', 'blocks.17.conv2.bn.weight', 'blocks.17.conv2.bn.bias', 'blocks.17.conv2.bn.running_mean', 'blocks.17.conv2.bn.running_var', 'blocks.17.conv2.bn.num_batches_tracked', 'blocks.17.conv3.conv.weight', 'blocks.17.conv3.bn.weight', 'blocks.17.conv3.bn.bias', 'blocks.17.conv3.bn.running_mean', 'blocks.17.conv3.bn.running_var', 'blocks.17.conv3.bn.num_batches_tracked', 'classifier.linear.weight', 'classifier.linear.bias'])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-072aaaceedb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mst_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./weight_after_ps.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mst_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmax_subnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mst_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmax_subnet_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_subnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_subnet_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fp32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ofa/imagenet_classification/networks/resnets.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                 \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResNets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1224\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1225\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNets:\n\tsize mismatch for blocks.0.conv1.conv.weight: copying a param with shape torch.Size([80, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([88, 64, 1, 1]).\n\tsize mismatch for blocks.0.conv1.bn.weight: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.0.conv1.bn.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.0.conv1.bn.running_mean: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.0.conv1.bn.running_var: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.0.conv2.conv.weight: copying a param with shape torch.Size([80, 80, 3, 3]) from checkpoint, the shape in current model is torch.Size([88, 88, 3, 3]).\n\tsize mismatch for blocks.0.conv2.bn.weight: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.0.conv2.bn.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.0.conv2.bn.running_mean: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.0.conv2.bn.running_var: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.0.conv3.conv.weight: copying a param with shape torch.Size([208, 80, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 88, 1, 1]).\n\tsize mismatch for blocks.0.conv3.bn.weight: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for blocks.0.conv3.bn.bias: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for blocks.0.conv3.bn.running_mean: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for blocks.0.conv3.bn.running_var: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for blocks.0.downsample.conv.weight: copying a param with shape torch.Size([208, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 64, 1, 1]).\n\tsize mismatch for blocks.0.downsample.bn.weight: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for blocks.0.downsample.bn.bias: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for blocks.0.downsample.bn.running_mean: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for blocks.0.downsample.bn.running_var: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for blocks.1.conv1.conv.weight: copying a param with shape torch.Size([80, 208, 1, 1]) from checkpoint, the shape in current model is torch.Size([88, 256, 1, 1]).\n\tsize mismatch for blocks.1.conv1.bn.weight: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.1.conv1.bn.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.1.conv1.bn.running_mean: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.1.conv1.bn.running_var: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.1.conv2.conv.weight: copying a param with shape torch.Size([80, 80, 3, 3]) from checkpoint, the shape in current model is torch.Size([88, 88, 3, 3]).\n\tsize mismatch for blocks.1.conv2.bn.weight: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.1.conv2.bn.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.1.conv2.bn.running_mean: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.1.conv2.bn.running_var: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.1.conv3.conv.weight: copying a param with shape torch.Size([208, 80, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 88, 1, 1]).\n\tsize mismatch for blocks.1.conv3.bn.weight: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for blocks.1.conv3.bn.bias: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for blocks.1.conv3.bn.running_mean: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for blocks.1.conv3.bn.running_var: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for blocks.2.conv1.conv.weight: copying a param with shape torch.Size([80, 208, 1, 1]) from checkpoint, the shape in current model is torch.Size([88, 256, 1, 1]).\n\tsize mismatch for blocks.2.conv1.bn.weight: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.2.conv1.bn.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.2.conv1.bn.running_mean: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.2.conv1.bn.running_var: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.2.conv2.conv.weight: copying a param with shape torch.Size([80, 80, 3, 3]) from checkpoint, the shape in current model is torch.Size([88, 88, 3, 3]).\n\tsize mismatch for blocks.2.conv2.bn.weight: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.2.conv2.bn.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.2.conv2.bn.running_mean: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.2.conv2.bn.running_var: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.2.conv3.conv.weight: copying a param with shape torch.Size([208, 80, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 88, 1, 1]).\n\tsize mismatch for blocks.2.conv3.bn.weight: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for blocks.2.conv3.bn.bias: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for blocks.2.conv3.bn.running_mean: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for blocks.2.conv3.bn.running_var: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for blocks.3.conv1.conv.weight: copying a param with shape torch.Size([80, 208, 1, 1]) from checkpoint, the shape in current model is torch.Size([88, 256, 1, 1]).\n\tsize mismatch for blocks.3.conv1.bn.weight: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.3.conv1.bn.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.3.conv1.bn.running_mean: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.3.conv1.bn.running_var: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.3.conv2.conv.weight: copying a param with shape torch.Size([80, 80, 3, 3]) from checkpoint, the shape in current model is torch.Size([88, 88, 3, 3]).\n\tsize mismatch for blocks.3.conv2.bn.weight: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.3.conv2.bn.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.3.conv2.bn.running_mean: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.3.conv2.bn.running_var: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([88]).\n\tsize mismatch for blocks.3.conv3.conv.weight: copying a param with shape torch.Size([208, 80, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 88, 1, 1]).\n\tsize mismatch for blocks.3.conv3.bn.weight: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for blocks.3.conv3.bn.bias: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for blocks.3.conv3.bn.running_mean: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for blocks.3.conv3.bn.running_var: copying a param with shape torch.Size([208]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for blocks.4.conv1.conv.weight: copying a param with shape torch.Size([160, 208, 1, 1]) from checkpoint, the shape in current model is torch.Size([176, 256, 1, 1]).\n\tsize mismatch for blocks.4.conv1.bn.weight: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.4.conv1.bn.bias: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.4.conv1.bn.running_mean: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.4.conv1.bn.running_var: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.4.conv2.conv.weight: copying a param with shape torch.Size([160, 160, 3, 3]) from checkpoint, the shape in current model is torch.Size([176, 176, 3, 3]).\n\tsize mismatch for blocks.4.conv2.bn.weight: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.4.conv2.bn.bias: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.4.conv2.bn.running_mean: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.4.conv2.bn.running_var: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.4.conv3.conv.weight: copying a param with shape torch.Size([408, 160, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 176, 1, 1]).\n\tsize mismatch for blocks.4.conv3.bn.weight: copying a param with shape torch.Size([408]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.4.conv3.bn.bias: copying a param with shape torch.Size([408]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.4.conv3.bn.running_mean: copying a param with shape torch.Size([408]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.4.conv3.bn.running_var: copying a param with shape torch.Size([408]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.4.downsample.conv.weight: copying a param with shape torch.Size([408, 208, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n\tsize mismatch for blocks.4.downsample.bn.weight: copying a param with shape torch.Size([408]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.4.downsample.bn.bias: copying a param with shape torch.Size([408]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.4.downsample.bn.running_mean: copying a param with shape torch.Size([408]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.4.downsample.bn.running_var: copying a param with shape torch.Size([408]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.5.conv1.conv.weight: copying a param with shape torch.Size([160, 408, 1, 1]) from checkpoint, the shape in current model is torch.Size([176, 512, 1, 1]).\n\tsize mismatch for blocks.5.conv1.bn.weight: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.5.conv1.bn.bias: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.5.conv1.bn.running_mean: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.5.conv1.bn.running_var: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.5.conv2.conv.weight: copying a param with shape torch.Size([160, 160, 3, 3]) from checkpoint, the shape in current model is torch.Size([176, 176, 3, 3]).\n\tsize mismatch for blocks.5.conv2.bn.weight: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.5.conv2.bn.bias: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.5.conv2.bn.running_mean: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.5.conv2.bn.running_var: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.5.conv3.conv.weight: copying a param with shape torch.Size([408, 160, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 176, 1, 1]).\n\tsize mismatch for blocks.5.conv3.bn.weight: copying a param with shape torch.Size([408]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.5.conv3.bn.bias: copying a param with shape torch.Size([408]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.5.conv3.bn.running_mean: copying a param with shape torch.Size([408]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.5.conv3.bn.running_var: copying a param with shape torch.Size([408]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.6.conv1.conv.weight: copying a param with shape torch.Size([160, 408, 1, 1]) from checkpoint, the shape in current model is torch.Size([176, 512, 1, 1]).\n\tsize mismatch for blocks.6.conv1.bn.weight: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.6.conv1.bn.bias: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.6.conv1.bn.running_mean: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.6.conv1.bn.running_var: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.6.conv2.conv.weight: copying a param with shape torch.Size([160, 160, 3, 3]) from checkpoint, the shape in current model is torch.Size([176, 176, 3, 3]).\n\tsize mismatch for blocks.6.conv2.bn.weight: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.6.conv2.bn.bias: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.6.conv2.bn.running_mean: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.6.conv2.bn.running_var: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.6.conv3.conv.weight: copying a param with shape torch.Size([408, 160, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 176, 1, 1]).\n\tsize mismatch for blocks.6.conv3.bn.weight: copying a param with shape torch.Size([408]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.6.conv3.bn.bias: copying a param with shape torch.Size([408]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.6.conv3.bn.running_mean: copying a param with shape torch.Size([408]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.6.conv3.bn.running_var: copying a param with shape torch.Size([408]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.7.conv1.conv.weight: copying a param with shape torch.Size([160, 408, 1, 1]) from checkpoint, the shape in current model is torch.Size([176, 512, 1, 1]).\n\tsize mismatch for blocks.7.conv1.bn.weight: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.7.conv1.bn.bias: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.7.conv1.bn.running_mean: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.7.conv1.bn.running_var: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.7.conv2.conv.weight: copying a param with shape torch.Size([160, 160, 3, 3]) from checkpoint, the shape in current model is torch.Size([176, 176, 3, 3]).\n\tsize mismatch for blocks.7.conv2.bn.weight: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.7.conv2.bn.bias: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.7.conv2.bn.running_mean: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.7.conv2.bn.running_var: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([176]).\n\tsize mismatch for blocks.7.conv3.conv.weight: copying a param with shape torch.Size([408, 160, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 176, 1, 1]).\n\tsize mismatch for blocks.7.conv3.bn.weight: copying a param with shape torch.Size([408]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.7.conv3.bn.bias: copying a param with shape torch.Size([408]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.7.conv3.bn.running_mean: copying a param with shape torch.Size([408]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.7.conv3.bn.running_var: copying a param with shape torch.Size([408]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for blocks.8.conv1.conv.weight: copying a param with shape torch.Size([328, 408, 1, 1]) from checkpoint, the shape in current model is torch.Size([360, 512, 1, 1]).\n\tsize mismatch for blocks.8.conv1.bn.weight: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.8.conv1.bn.bias: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.8.conv1.bn.running_mean: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.8.conv1.bn.running_var: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.8.conv2.conv.weight: copying a param with shape torch.Size([328, 328, 3, 3]) from checkpoint, the shape in current model is torch.Size([360, 360, 3, 3]).\n\tsize mismatch for blocks.8.conv2.bn.weight: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.8.conv2.bn.bias: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.8.conv2.bn.running_mean: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.8.conv2.bn.running_var: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.8.conv3.conv.weight: copying a param with shape torch.Size([816, 328, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 360, 1, 1]).\n\tsize mismatch for blocks.8.conv3.bn.weight: copying a param with shape torch.Size([816]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.8.conv3.bn.bias: copying a param with shape torch.Size([816]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.8.conv3.bn.running_mean: copying a param with shape torch.Size([816]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.8.conv3.bn.running_var: copying a param with shape torch.Size([816]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.8.downsample.conv.weight: copying a param with shape torch.Size([816, 408, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).\n\tsize mismatch for blocks.8.downsample.bn.weight: copying a param with shape torch.Size([816]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.8.downsample.bn.bias: copying a param with shape torch.Size([816]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.8.downsample.bn.running_mean: copying a param with shape torch.Size([816]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.8.downsample.bn.running_var: copying a param with shape torch.Size([816]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.9.conv1.conv.weight: copying a param with shape torch.Size([328, 816, 1, 1]) from checkpoint, the shape in current model is torch.Size([360, 1024, 1, 1]).\n\tsize mismatch for blocks.9.conv1.bn.weight: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.9.conv1.bn.bias: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.9.conv1.bn.running_mean: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.9.conv1.bn.running_var: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.9.conv2.conv.weight: copying a param with shape torch.Size([328, 328, 3, 3]) from checkpoint, the shape in current model is torch.Size([360, 360, 3, 3]).\n\tsize mismatch for blocks.9.conv2.bn.weight: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.9.conv2.bn.bias: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.9.conv2.bn.running_mean: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.9.conv2.bn.running_var: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.9.conv3.conv.weight: copying a param with shape torch.Size([816, 328, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 360, 1, 1]).\n\tsize mismatch for blocks.9.conv3.bn.weight: copying a param with shape torch.Size([816]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.9.conv3.bn.bias: copying a param with shape torch.Size([816]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.9.conv3.bn.running_mean: copying a param with shape torch.Size([816]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.9.conv3.bn.running_var: copying a param with shape torch.Size([816]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.10.conv1.conv.weight: copying a param with shape torch.Size([328, 816, 1, 1]) from checkpoint, the shape in current model is torch.Size([360, 1024, 1, 1]).\n\tsize mismatch for blocks.10.conv1.bn.weight: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.10.conv1.bn.bias: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.10.conv1.bn.running_mean: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.10.conv1.bn.running_var: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.10.conv2.conv.weight: copying a param with shape torch.Size([328, 328, 3, 3]) from checkpoint, the shape in current model is torch.Size([360, 360, 3, 3]).\n\tsize mismatch for blocks.10.conv2.bn.weight: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.10.conv2.bn.bias: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.10.conv2.bn.running_mean: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.10.conv2.bn.running_var: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.10.conv3.conv.weight: copying a param with shape torch.Size([816, 328, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 360, 1, 1]).\n\tsize mismatch for blocks.10.conv3.bn.weight: copying a param with shape torch.Size([816]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.10.conv3.bn.bias: copying a param with shape torch.Size([816]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.10.conv3.bn.running_mean: copying a param with shape torch.Size([816]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.10.conv3.bn.running_var: copying a param with shape torch.Size([816]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.11.conv1.conv.weight: copying a param with shape torch.Size([328, 816, 1, 1]) from checkpoint, the shape in current model is torch.Size([360, 1024, 1, 1]).\n\tsize mismatch for blocks.11.conv1.bn.weight: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.11.conv1.bn.bias: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.11.conv1.bn.running_mean: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.11.conv1.bn.running_var: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.11.conv2.conv.weight: copying a param with shape torch.Size([328, 328, 3, 3]) from checkpoint, the shape in current model is torch.Size([360, 360, 3, 3]).\n\tsize mismatch for blocks.11.conv2.bn.weight: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.11.conv2.bn.bias: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.11.conv2.bn.running_mean: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.11.conv2.bn.running_var: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.11.conv3.conv.weight: copying a param with shape torch.Size([816, 328, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 360, 1, 1]).\n\tsize mismatch for blocks.11.conv3.bn.weight: copying a param with shape torch.Size([816]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.11.conv3.bn.bias: copying a param with shape torch.Size([816]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.11.conv3.bn.running_mean: copying a param with shape torch.Size([816]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.11.conv3.bn.running_var: copying a param with shape torch.Size([816]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.12.conv1.conv.weight: copying a param with shape torch.Size([328, 816, 1, 1]) from checkpoint, the shape in current model is torch.Size([360, 1024, 1, 1]).\n\tsize mismatch for blocks.12.conv1.bn.weight: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.12.conv1.bn.bias: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.12.conv1.bn.running_mean: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.12.conv1.bn.running_var: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.12.conv2.conv.weight: copying a param with shape torch.Size([328, 328, 3, 3]) from checkpoint, the shape in current model is torch.Size([360, 360, 3, 3]).\n\tsize mismatch for blocks.12.conv2.bn.weight: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.12.conv2.bn.bias: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.12.conv2.bn.running_mean: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.12.conv2.bn.running_var: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.12.conv3.conv.weight: copying a param with shape torch.Size([816, 328, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 360, 1, 1]).\n\tsize mismatch for blocks.12.conv3.bn.weight: copying a param with shape torch.Size([816]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.12.conv3.bn.bias: copying a param with shape torch.Size([816]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.12.conv3.bn.running_mean: copying a param with shape torch.Size([816]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.12.conv3.bn.running_var: copying a param with shape torch.Size([816]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.13.conv1.conv.weight: copying a param with shape torch.Size([328, 816, 1, 1]) from checkpoint, the shape in current model is torch.Size([360, 1024, 1, 1]).\n\tsize mismatch for blocks.13.conv1.bn.weight: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.13.conv1.bn.bias: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.13.conv1.bn.running_mean: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.13.conv1.bn.running_var: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.13.conv2.conv.weight: copying a param with shape torch.Size([328, 328, 3, 3]) from checkpoint, the shape in current model is torch.Size([360, 360, 3, 3]).\n\tsize mismatch for blocks.13.conv2.bn.weight: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.13.conv2.bn.bias: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.13.conv2.bn.running_mean: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.13.conv2.bn.running_var: copying a param with shape torch.Size([328]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.13.conv3.conv.weight: copying a param with shape torch.Size([816, 328, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 360, 1, 1]).\n\tsize mismatch for blocks.13.conv3.bn.weight: copying a param with shape torch.Size([816]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.13.conv3.bn.bias: copying a param with shape torch.Size([816]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.13.conv3.bn.running_mean: copying a param with shape torch.Size([816]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.13.conv3.bn.running_var: copying a param with shape torch.Size([816]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for blocks.14.conv1.conv.weight: copying a param with shape torch.Size([656, 816, 1, 1]) from checkpoint, the shape in current model is torch.Size([720, 1024, 1, 1]).\n\tsize mismatch for blocks.14.conv1.bn.weight: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.14.conv1.bn.bias: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.14.conv1.bn.running_mean: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.14.conv1.bn.running_var: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.14.conv2.conv.weight: copying a param with shape torch.Size([656, 656, 3, 3]) from checkpoint, the shape in current model is torch.Size([720, 720, 3, 3]).\n\tsize mismatch for blocks.14.conv2.bn.weight: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.14.conv2.bn.bias: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.14.conv2.bn.running_mean: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.14.conv2.bn.running_var: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.14.conv3.conv.weight: copying a param with shape torch.Size([1640, 656, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 720, 1, 1]).\n\tsize mismatch for blocks.14.conv3.bn.weight: copying a param with shape torch.Size([1640]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for blocks.14.conv3.bn.bias: copying a param with shape torch.Size([1640]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for blocks.14.conv3.bn.running_mean: copying a param with shape torch.Size([1640]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for blocks.14.conv3.bn.running_var: copying a param with shape torch.Size([1640]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for blocks.14.downsample.conv.weight: copying a param with shape torch.Size([1640, 816, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 1, 1]).\n\tsize mismatch for blocks.14.downsample.bn.weight: copying a param with shape torch.Size([1640]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for blocks.14.downsample.bn.bias: copying a param with shape torch.Size([1640]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for blocks.14.downsample.bn.running_mean: copying a param with shape torch.Size([1640]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for blocks.14.downsample.bn.running_var: copying a param with shape torch.Size([1640]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for blocks.15.conv1.conv.weight: copying a param with shape torch.Size([656, 1640, 1, 1]) from checkpoint, the shape in current model is torch.Size([720, 2048, 1, 1]).\n\tsize mismatch for blocks.15.conv1.bn.weight: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.15.conv1.bn.bias: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.15.conv1.bn.running_mean: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.15.conv1.bn.running_var: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.15.conv2.conv.weight: copying a param with shape torch.Size([656, 656, 3, 3]) from checkpoint, the shape in current model is torch.Size([720, 720, 3, 3]).\n\tsize mismatch for blocks.15.conv2.bn.weight: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.15.conv2.bn.bias: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.15.conv2.bn.running_mean: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.15.conv2.bn.running_var: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.15.conv3.conv.weight: copying a param with shape torch.Size([1640, 656, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 720, 1, 1]).\n\tsize mismatch for blocks.15.conv3.bn.weight: copying a param with shape torch.Size([1640]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for blocks.15.conv3.bn.bias: copying a param with shape torch.Size([1640]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for blocks.15.conv3.bn.running_mean: copying a param with shape torch.Size([1640]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for blocks.15.conv3.bn.running_var: copying a param with shape torch.Size([1640]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for blocks.16.conv1.conv.weight: copying a param with shape torch.Size([656, 1640, 1, 1]) from checkpoint, the shape in current model is torch.Size([720, 2048, 1, 1]).\n\tsize mismatch for blocks.16.conv1.bn.weight: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.16.conv1.bn.bias: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.16.conv1.bn.running_mean: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.16.conv1.bn.running_var: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.16.conv2.conv.weight: copying a param with shape torch.Size([656, 656, 3, 3]) from checkpoint, the shape in current model is torch.Size([720, 720, 3, 3]).\n\tsize mismatch for blocks.16.conv2.bn.weight: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.16.conv2.bn.bias: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.16.conv2.bn.running_mean: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.16.conv2.bn.running_var: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.16.conv3.conv.weight: copying a param with shape torch.Size([1640, 656, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 720, 1, 1]).\n\tsize mismatch for blocks.16.conv3.bn.weight: copying a param with shape torch.Size([1640]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for blocks.16.conv3.bn.bias: copying a param with shape torch.Size([1640]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for blocks.16.conv3.bn.running_mean: copying a param with shape torch.Size([1640]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for blocks.16.conv3.bn.running_var: copying a param with shape torch.Size([1640]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for blocks.17.conv1.conv.weight: copying a param with shape torch.Size([656, 1640, 1, 1]) from checkpoint, the shape in current model is torch.Size([720, 2048, 1, 1]).\n\tsize mismatch for blocks.17.conv1.bn.weight: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.17.conv1.bn.bias: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.17.conv1.bn.running_mean: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.17.conv1.bn.running_var: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.17.conv2.conv.weight: copying a param with shape torch.Size([656, 656, 3, 3]) from checkpoint, the shape in current model is torch.Size([720, 720, 3, 3]).\n\tsize mismatch for blocks.17.conv2.bn.weight: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.17.conv2.bn.bias: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.17.conv2.bn.running_mean: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.17.conv2.bn.running_var: copying a param with shape torch.Size([656]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.17.conv3.conv.weight: copying a param with shape torch.Size([1640, 656, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 720, 1, 1]).\n\tsize mismatch for blocks.17.conv3.bn.weight: copying a param with shape torch.Size([1640]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for blocks.17.conv3.bn.bias: copying a param with shape torch.Size([1640]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for blocks.17.conv3.bn.running_mean: copying a param with shape torch.Size([1640]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for blocks.17.conv3.bn.running_var: copying a param with shape torch.Size([1640]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for classifier.linear.weight: copying a param with shape torch.Size([1000, 1640]) from checkpoint, the shape in current model is torch.Size([1000, 2048])."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00tkyMpU1_bM"
      },
      "source": [
        ""
      ],
      "id": "00tkyMpU1_bM",
      "execution_count": null,
      "outputs": []
    }
  ]
}