{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "ofa_quant.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monishramadoss/ofa_quant/blob/main/ofa_quant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BesMFL3fVdax",
        "outputId": "8451a816-ca51-4a13-9755-d528037bb46f"
      },
      "source": [
        "!pip install torch==1.8.1 torchvision==0.9.1\n",
        "!pip install ofa==0.0.4-2012082155\n",
        "! git clone https://github.com/seshuad/IMagenet\n",
        "! ls 'IMagenet/tiny-imagenet-200/'"
      ],
      "id": "BesMFL3fVdax",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (1.8.1)\n",
            "Requirement already satisfied: torchvision==0.9.1 in /usr/local/lib/python3.7/dist-packages (0.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (3.10.0.2)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.1) (7.1.2)\n",
            "Requirement already satisfied: ofa==0.0.4-2012082155 in /usr/local/lib/python3.7/dist-packages (0.0.4.post2012082155)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from ofa==0.0.4-2012082155) (1.8.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->ofa==0.0.4-2012082155) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->ofa==0.0.4-2012082155) (1.19.5)\n",
            "fatal: destination path 'IMagenet' already exists and is not an empty directory.\n",
            "test  train  val  wnids.txt  words.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp77tl4giVWJ",
        "outputId": "8dbf3b83-246f-46eb-f459-8335dc0a07ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import time\n",
        "import skimage.io as nd\n",
        "import numpy as np\n",
        "import torch\n",
        "import skimage.color\n",
        "\n",
        "\n",
        "path = 'IMagenet/tiny-imagenet-200/'\n",
        "\n",
        "def get_id_dictionary():\n",
        "    id_dict = {}\n",
        "    for i, line in enumerate(open( path + 'wnids.txt', 'r')):\n",
        "        id_dict[line.replace('\\n', '')] = i\n",
        "    return id_dict\n",
        "  \n",
        "def get_class_to_id_dict():\n",
        "    id_dict = get_id_dictionary()\n",
        "    all_classes = {}\n",
        "    result = {}\n",
        "    for i, line in enumerate(open( path + 'words.txt', 'r')):\n",
        "        n_id, word = line.split('\\t')[:2]\n",
        "        all_classes[n_id] = word\n",
        "    for key, value in id_dict.items():\n",
        "        result[value] = (key, all_classes[key])      \n",
        "    return result\n",
        "\n",
        "def get_data(id_dict):\n",
        "    print('starting loading data')\n",
        "    train_data, test_data = [], []\n",
        "    train_labels, test_labels = [], []\n",
        "    t = time.time()\n",
        "    for key, value in id_dict.items():\n",
        "        train_data += [nd.imread( path + 'train/{}/images/{}_{}.JPEG'.format(key, key, str(i)), as_gray=False ) for i in range(500)]\n",
        "        train_labels_ = np.array([[0]*200]*500)\n",
        "        train_labels_[:, value] = 1\n",
        "        train_labels += train_labels_.tolist()\n",
        "\n",
        "    for line in open( path + 'val/val_annotations.txt'):\n",
        "        img_name, class_id = line.split('\\t')[:2]\n",
        "        test_data += [nd.imread( path + 'val/images/{}'.format(img_name), as_gray=False)]\n",
        "        \n",
        "        # test_data.append(test_data_)\n",
        "        test_labels_ = np.array([[0]*200])\n",
        "        test_labels_[0, id_dict[class_id]] = 1\n",
        "        test_labels += test_labels_.tolist()\n",
        "\n",
        "    for i in range(len(test_data)):\n",
        "        if test_data[i].ndim == 2:\n",
        "            test_data[i] = skimage.color.gray2rgb(test_data[i])\n",
        "\n",
        "    for i in range(len(train_data)):\n",
        "        if train_data[i].ndim == 2:\n",
        "            train_data[i] = skimage.color.gray2rgb(train_data[i])\n",
        "\n",
        "    print('finished loading data, in {} seconds'.format(time.time() - t))\n",
        "    return np.array(train_data), np.array(train_labels), np.array(test_data), np.array(test_labels)\n",
        "\n",
        "def evaluate(model, data, target):\n",
        "    model.eval()  # set model in eval mode\n",
        "    total_time = 0\n",
        "    num_correct = 0  # total 1000\n",
        "    with torch.no_grad():\n",
        "        for image, target in zip(data, target):\n",
        "            # print(data[0].shape)\n",
        "            start = time.time()\n",
        "            image = torch.tensor(image)\n",
        "            target = torch.tensor(target)\n",
        "            result = model(image)\n",
        "            total_time += time.time() - start\n",
        "            \n",
        "            prediction = idx2label[int(result[0].sort()[1][-1:])]\n",
        "            if target == prediction:\n",
        "                num_correct += 1\n",
        "    \n",
        "    inference_time = total_time / len(data)\n",
        "    accuracy = num_correct / len(data)\n",
        "    return inference_time, accuracy\n",
        "\n",
        "train_data, train_labels, test_data, test_labels = get_data(get_id_dictionary())"
      ],
      "id": "Kp77tl4giVWJ",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting loading data\n",
            "finished loading data, in 56.29645776748657 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98SBhCpxVfeu"
      },
      "source": [
        "import copy\n",
        "import torch\n",
        "from ofa.model_zoo import ofa_net\n",
        "from ofa.imagenet_classification.data_providers.imagenet import ImagenetDataProvider\n",
        "from ofa.imagenet_classification.run_manager import ImagenetRunConfig, RunManager\n",
        "\n",
        "raw_resnet = ofa_net('ofa_resnet50', pretrained=True)\n",
        "config = 'fbgemm'"
      ],
      "id": "98SBhCpxVfeu",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGw3VCBgash7"
      },
      "source": [
        "from ofa.imagenet_classification.networks import ResNets\n",
        "from ofa.utils.layers import IdentityLayer, ResidualBlock\n",
        "\n",
        "def val2list(val, repeat_time=1):\n",
        "    if isinstance(val, list) or isinstance(val, np.ndarray):\n",
        "        return val\n",
        "    elif isinstance(val, tuple):\n",
        "        return list(val)\n",
        "    else:\n",
        "        return [val for _ in range(repeat_time)]\n",
        "\n",
        "def set_active_subnet(ofa, d=None, e=None, w=None, **kwargs):\n",
        "    depth = val2list(d, len(ofa.BASE_DEPTH_LIST) + 1)\n",
        "    expand_ratio = val2list(e, len(ofa.blocks))\n",
        "    width_mult = val2list(w, len(ofa.BASE_DEPTH_LIST) + 2)\n",
        "    for block, e in zip(ofa.blocks, expand_ratio):\n",
        "        if e is not None:\n",
        "            block.active_expand_ratio = e\n",
        "\n",
        "    if width_mult[0] is not None:\n",
        "        ofa.input_stem[1].conv.active_out_channel = ofa.input_stem[0].active_out_channel = \\\n",
        "            ofa.input_stem[0].out_channel_list[width_mult[0]]\n",
        "    if width_mult[1] is not None:\n",
        "        ofa.input_stem[2].active_out_channel = ofa.input_stem[2].out_channel_list[width_mult[1]]\n",
        "\n",
        "    if depth[0] is not None:\n",
        "        ofa.input_stem_skipping = (depth[0] != max(ofa.depth_list))\n",
        "    for stage_id, (block_idx, d, w) in enumerate(zip(ofa.grouped_block_index, depth[1:], width_mult[2:])):\n",
        "        if d is not None:\n",
        "            ofa.runtime_depth[stage_id] = max(ofa.depth_list) - d\n",
        "        if w is not None:\n",
        "            for idx in block_idx:\n",
        "                ofa.blocks[idx].active_out_channel = ofa.blocks[idx].out_channel_list[w]\n",
        "\n",
        "def set_max_subnet(ofa):\n",
        "    set_active_subnet(ofa, max(ofa.depth_list), max(ofa.expand_ratio_list), len(ofa.width_mult_list) - 1)\n",
        "\n",
        "def get_active_subnet(ofa, preserve_weight=True):\n",
        "    input_stem = [ofa.input_stem[0].get_active_subnet(3, preserve_weight)]\n",
        "    active_out = ofa.input_stem[0].active_out_channel\n",
        "    input_stem_blocks = [(0, active_out)]\n",
        "    \n",
        "    if ofa.input_stem_skipping <= 0:        \n",
        "        input_stem.append(ResidualBlock(\n",
        "            ofa.input_stem[1].conv.get_active_subnet(active_out, preserve_weight),\n",
        "            IdentityLayer(active_out, active_out)\n",
        "        ))\n",
        "        input_stem_blocks += [(1, active_out)]\n",
        "    input_stem.append(ofa.input_stem[2].get_active_subnet(active_out, preserve_weight))\n",
        "    input_channel = ofa.input_stem[2].active_out_channel\n",
        "    input_stem_blocks += [(2, input_channel)]\n",
        " \n",
        "    blocks = []\n",
        "    block_groups = []\n",
        "    block_input_channel = {}\n",
        "    for stage_id, block_idx in enumerate(ofa.grouped_block_index):\n",
        "        depth_param = ofa.runtime_depth[stage_id]\n",
        "        active_idx = block_idx[:len(block_idx) - depth_param]\n",
        "        block_groups+= active_idx\n",
        "        for idx in active_idx:\n",
        "            block_input_channel[idx] = input_channel\n",
        "            blocks.append(ofa.blocks[idx].get_active_subnet(input_channel, preserve_weight))            \n",
        "            input_channel = ofa.blocks[idx].active_out_channel\n",
        "                 \n",
        "    classifier = ofa.classifier.get_active_subnet(input_channel, preserve_weight)\n",
        "\n",
        "    subnet = ResNets(input_stem, blocks, classifier)\n",
        "    subnet.set_bn_param(**ofa.get_bn_param())\n",
        "    subnet.input_stem_blocks = dict(input_stem_blocks)\n",
        "    subnet.block_groups = block_groups\n",
        "    subnet.block_input_channel = block_input_channel\n",
        "    return subnet\n"
      ],
      "id": "mGw3VCBgash7",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtfizHWm16D_"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "def nested_children(m: torch.nn.Module):\n",
        "    children = dict(m.named_children())\n",
        "    output = {}\n",
        "    if children == {}:\n",
        "        return m\n",
        "    else:\n",
        "        for name, child in children.items():\n",
        "            try:\n",
        "                output[name] = nested_children(child)\n",
        "            except TypeError:\n",
        "                output[name] = nested_children(child)\n",
        "    return output\n",
        "\n",
        "def squash_nested_dict(nested_dict, ret_lst={}, prefix='', mod=None):\n",
        "    if nested_dict == {}:\n",
        "        ret_lst[prefix[1:]] = mod\n",
        "        return\n",
        "    for k in nested_dict.keys():\n",
        "        if isinstance(nested_dict[k], dict):\n",
        "            squash_nested_dict(nested_dict[k], ret_lst, prefix+'.'+k)\n",
        "        else:\n",
        "            squash_nested_dict({}, ret_lst, prefix+'.'+k, nested_dict[k])\n",
        "\n",
        "def remap_weight_names(mappings, dict1):\n",
        "    input_stem = mappings['input_stem']\n",
        "    block = mappings['blocks']\n",
        "    map = dict1.copy()\n",
        "    tmp = {}\n",
        "    for i, (input_id, channel) in enumerate(input_stem.items()):\n",
        "        tmp[str(input_id)] = map['input_stem'][str(i)]\n",
        "    \n",
        "    map['input_stem'] = tmp\n",
        "    tmp = {}\n",
        "    for i in map['blocks']:\n",
        "        idx = block[int(i)]\n",
        "        tmp[str(idx)] = map['blocks'][i]\n",
        "    \n",
        "    map['blocks'] = tmp\n",
        "    return map\n",
        "\n",
        "class Quant_Model(nn.Module):\n",
        "    def __init__(self, quat_model, float_model):\n",
        "        super(Quant_Model, self).__init__()\n",
        "        self.input_zero_points = {}\n",
        "        self.input_scales = {}\n",
        "        self.float_model = float_model\n",
        "        self.quant_model = quat_model\n",
        "        self.quant_state_dict = quat_model.state_dict()\n",
        "\n",
        "        layer_names = {}\n",
        "        _layers = nested_children(self.float_model)\n",
        "        squash_nested_dict(_layers, layer_names)\n",
        "        \n",
        "        _quant_layers = nested_children(self.quant_model)\n",
        "        \n",
        "        _remap = remap_weight_names({\n",
        "            'input_stem':self.float_model.input_stem_blocks,\n",
        "            'blocks': self.float_model.block_groups,\n",
        "        }, _layers)\n",
        "\n",
        "        _remap_names = {}\n",
        "        squash_nested_dict(_remap, _remap_names)\n",
        "        \n",
        "        # for l1, l2 in zip(layer_names.keys(), _remap_names.keys()):\n",
        "        #     print(l1, l2)\n",
        "        \n",
        "        self._remapped_layer_names = dict(zip(layer_names.keys(), _remap_names.keys()))\n",
        "\n",
        "        for i, l in enumerate(list(layer_names.keys())):\n",
        "            layer_names[l].register_forward_pre_hook(self.forward_pre_hook(l))\n",
        "\n",
        "\n",
        "    def forward_pre_hook(self, layer_name):\n",
        "        def pre_hook(module, x):\n",
        "            if isinstance(module, nn.Conv2d) or isinstance(module, nn.Identity):\n",
        "                with torch.no_grad():\n",
        "                    quant_model_layer = self._remapped_layer_names[layer_name]\n",
        "                    zero_point = self.quant_state_dict[quant_model_layer+'.zero_point'].float()\n",
        "                    scale = self.quant_state_dict[quant_model_layer+'.scale'].float()\n",
        "                    quant_min = 0.0\n",
        "                    quant_max = 1.0\n",
        "                    tmp = torch.clamp(torch.round(torch.div(x[0], scale) + zero_point), quant_min, quant_max) - zero_point\n",
        "                    x = tmp*scale\n",
        "            return x\n",
        "        return pre_hook\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.float_model(x)\n",
        "\n"
      ],
      "id": "FtfizHWm16D_",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOLbEMvy_L_O",
        "outputId": "288b7ecd-cd41-4e71-fd2f-406efc6a6856",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "set_max_subnet(raw_resnet)\n",
        "max_subnet = get_active_subnet(raw_resnet)\n",
        "max_subnet.eval()\n",
        "max_subnet.qconfig = torch.quantization.get_default_qconfig(config)\n",
        "\n",
        "set_active_subnet(raw_resnet, 0, 0, 0)\n",
        "min_subnet = get_active_subnet(raw_resnet)\n",
        "min_subnet.eval()\n",
        "min_subnet.qconfig = torch.quantization.get_default_qconfig(config)\n",
        "\n",
        "input_fp32 = torch.randn(1, 3, 224, 224, dtype=torch.float32)\n",
        "\n",
        "min_subnet_1 = torch.quantization.prepare(min_subnet)\n",
        "_ = min_subnet_1(input_fp32)\n",
        "quat_min_model = torch.quantization.convert(min_subnet_1)\n",
        "\n",
        "max_subnet_1 = torch.quantization.prepare(max_subnet)\n",
        "_ = max_subnet_1(input_fp32)\n",
        "quat_max_model = torch.quantization.convert(max_subnet_1)\n",
        "\n",
        "max_subnet.load_state_dict(torch.load('./large_subnet.pth'))\n",
        "\n",
        "fake_quant_model = Quant_Model(quat_max_model, min_subnet)\n",
        "fake_output = fake_quant_model(input_fp32)\n",
        "\n",
        "\n"
      ],
      "id": "SOLbEMvy_L_O",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/quantization/observer.py:123: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  reduce_range will be deprecated in a future release of PyTorch.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00tkyMpU1_bM",
        "outputId": "b34f4429-a5a9-41d1-8df6-ac2eabfc9db7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "source": [
        "ImagenetDataProvider.DEFAULT_PATH = path\n",
        "run_config = ImagenetRunConfig(test_batch_size=16, n_worker=20)\n",
        "run_config.data_provider.assign_active_img_size(224)\n",
        "\n",
        "run_manager = RunManager('./tmp/eval_subnet', quat_min_model, run_config, init=False)\n",
        "run_manager.reset_running_statistics(net=min_subnet) \n"
      ],
      "id": "00tkyMpU1_bM",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Color jitter: tf, resize_scale: 0.08, img_size: 224\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-fc0c758d13a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrun_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_provider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_active_img_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrun_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRunManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./tmp/eval_subnet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquat_min_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_running_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_subnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ofa/imagenet_classification/run_manager/run_manager.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, net, run_config, init, measure_latency, no_gpu)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# net info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mnet_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_net_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_provider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasure_latency\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s/net_info.txt'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mfout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ofa/utils/pytorch_utils.py\u001b[0m in \u001b[0;36mget_net_info\u001b[0;34m(net, input_shape, measure_latency, print_info)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;31m# flops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mnet_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'flops'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_net_flops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1e6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;31m# latencies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ofa/utils/pytorch_utils.py\u001b[0m in \u001b[0;36mcount_net_flops\u001b[0;34m(net, data_shape)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mflop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mflop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ofa/utils/flops_counter.py\u001b[0m in \u001b[0;36mprofile\u001b[0;34m(model, input_size, custom_ops)\u001b[0m\n\u001b[1;32m     70\u001b[0m                         \u001b[0mhandler_collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0moriginal_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mparameters\u001b[0;34m(self, recurse)\u001b[0m\n\u001b[1;32m   1259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m         \"\"\"\n\u001b[0;32m-> 1261\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1262\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_parameters\u001b[0;34m(self, prefix, recurse)\u001b[0m\n\u001b[1;32m   1285\u001b[0m             \u001b[0;32mlambda\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m             prefix=prefix, recurse=recurse)\n\u001b[0;32m-> 1287\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1288\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_named_members\u001b[0;34m(self, get_members_fn, prefix, recurse)\u001b[0m\n\u001b[1;32m   1230\u001b[0m         \u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1232\u001b[0;31m             \u001b[0mmembers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_members_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1233\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \"\"\"\n\u001b[1;32m   1284\u001b[0m         gen = self._named_members(\n\u001b[0;32m-> 1285\u001b[0;31m             \u001b[0;32mlambda\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m             prefix=prefix, recurse=recurse)\n\u001b[1;32m   1287\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    946\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 948\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Conv2d' object has no attribute '_parameters'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdCSc3Q7GHF2",
        "outputId": "af2328c5-e3ad-4e11-cfdb-b7a78d99eff6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        ""
      ],
      "id": "jdCSc3Q7GHF2",
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOuilXAwGKva"
      },
      "source": [
        ""
      ],
      "id": "pOuilXAwGKva",
      "execution_count": null,
      "outputs": []
    }
  ]
}