{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "ofa_quant.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monishramadoss/ofa_quant/blob/main/ofa_quant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BesMFL3fVdax",
        "outputId": "bbce3b5d-3bcd-45aa-c966-365cea68f5ea"
      },
      "source": [
        "!pip install torch==1.8.1 torchvision==0.9.1\n",
        "!pip install ofa==0.0.4-2012082155\n",
        "!pip install kaggle\n"
      ],
      "id": "BesMFL3fVdax",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (1.8.1)\n",
            "Requirement already satisfied: torchvision==0.9.1 in /usr/local/lib/python3.7/dist-packages (0.9.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.1) (7.1.2)\n",
            "Requirement already satisfied: ofa==0.0.4-2012082155 in /usr/local/lib/python3.7/dist-packages (0.0.4.post2012082155)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from ofa==0.0.4-2012082155) (1.8.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->ofa==0.0.4-2012082155) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->ofa==0.0.4-2012082155) (1.19.5)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8wy089SNoER",
        "outputId": "9329a57e-c9ae-4597-aa5e-641afa692e8b"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download ifigotin/imagenetmini-1000\n",
        "! unzip -qq imagenetmini-1000.zip \n",
        "! rm imagenetmini-1000.zip"
      ],
      "id": "B8wy089SNoER",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Downloading imagenetmini-1000.zip to /content\n",
            "100% 3.92G/3.92G [01:10<00:00, 21.9MB/s]\n",
            "100% 3.92G/3.92G [01:10<00:00, 59.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7rSfEp6NntC",
        "outputId": "2a7a127a-97b2-400e-c7bf-794faa51d426"
      },
      "source": [
        "! git clone https://github.com/seshuad/IMagenet\n",
        "! ls 'IMagenet/tiny-imagenet-200/'"
      ],
      "id": "a7rSfEp6NntC",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'IMagenet' already exists and is not an empty directory.\n",
            "test  train  val  wnids.txt  words.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp77tl4giVWJ"
      },
      "source": [
        "import time\n",
        "import skimage.io as nd\n",
        "import numpy as np\n",
        "import torch\n",
        "import skimage.color\n",
        "\n",
        "\n",
        "path = 'imagenet-mini/'\n",
        "\n",
        "def get_id_dictionary():\n",
        "    id_dict = {}\n",
        "    for i, line in enumerate(open( path + 'wnids.txt', 'r')):\n",
        "        id_dict[line.replace('\\n', '')] = i\n",
        "    return id_dict\n",
        "  \n",
        "def get_class_to_id_dict():\n",
        "    id_dict = get_id_dictionary()\n",
        "    all_classes = {}\n",
        "    result = {}\n",
        "    for i, line in enumerate(open( path + 'words.txt', 'r')):\n",
        "        n_id, word = line.split('\\t')[:2]\n",
        "        all_classes[n_id] = word\n",
        "    for key, value in id_dict.items():\n",
        "        result[value] = (key, all_classes[key])      \n",
        "    return result\n",
        "\n",
        "def get_data(id_dict):\n",
        "    print('starting loading data')\n",
        "    train_data, test_data = [], []\n",
        "    train_labels, test_labels = [], []\n",
        "    t = time.time()\n",
        "    for key, value in id_dict.items():\n",
        "        train_data += [nd.imread( path + 'train/{}/images/{}_{}.JPEG'.format(key, key, str(i)), as_gray=False ) for i in range(500)]\n",
        "        train_labels_ = np.array([[0]*200]*500)\n",
        "        train_labels_[:, value] = 1\n",
        "        train_labels += train_labels_.tolist()\n",
        "\n",
        "    for line in open( path + 'val/val_annotations.txt'):\n",
        "        img_name, class_id = line.split('\\t')[:2]\n",
        "        test_data += [nd.imread( path + 'val/images/{}'.format(img_name), as_gray=False)]\n",
        "        \n",
        "        # test_data.append(test_data_)\n",
        "        test_labels_ = np.array([[0]*200])\n",
        "        test_labels_[0, id_dict[class_id]] = 1\n",
        "        test_labels += test_labels_.tolist()\n",
        "\n",
        "    for i in range(len(test_data)):\n",
        "        if test_data[i].ndim == 2:\n",
        "            test_data[i] = skimage.color.gray2rgb(test_data[i])\n",
        "\n",
        "    for i in range(len(train_data)):\n",
        "        if train_data[i].ndim == 2:\n",
        "            train_data[i] = skimage.color.gray2rgb(train_data[i])\n",
        "\n",
        "    print('finished loading data, in {} seconds'.format(time.time() - t))\n",
        "    return np.array(train_data), np.array(train_labels), np.array(test_data), np.array(test_labels)\n",
        "\n",
        "def evaluate(model, data, target):\n",
        "    model.eval()  # set model in eval mode\n",
        "    total_time = 0\n",
        "    num_correct = 0  # total 1000\n",
        "    with torch.no_grad():\n",
        "        for image, target in zip(data, target):\n",
        "            # print(data[0].shape)\n",
        "            start = time.time()\n",
        "            image = torch.tensor(image)\n",
        "            target = torch.tensor(target)\n",
        "            result = model(image)\n",
        "            total_time += time.time() - start\n",
        "            \n",
        "            prediction = idx2label[int(result[0].sort()[1][-1:])]\n",
        "            if target == prediction:\n",
        "                num_correct += 1\n",
        "    \n",
        "    inference_time = total_time / len(data)\n",
        "    accuracy = num_correct / len(data)\n",
        "    return inference_time, accuracy\n",
        "\n"
      ],
      "id": "Kp77tl4giVWJ",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98SBhCpxVfeu"
      },
      "source": [
        "import copy\n",
        "import torch\n",
        "from ofa.model_zoo import ofa_net\n",
        "from ofa.imagenet_classification.data_providers.imagenet import ImagenetDataProvider\n",
        "from ofa.imagenet_classification.run_manager import ImagenetRunConfig, RunManager\n",
        "\n",
        "raw_resnet = ofa_net('ofa_resnet50', pretrained=True)\n",
        "config = 'fbgemm'"
      ],
      "id": "98SBhCpxVfeu",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGw3VCBgash7"
      },
      "source": [
        "from ofa.imagenet_classification.networks import ResNets\n",
        "from ofa.utils.layers import IdentityLayer, ResidualBlock\n",
        "\n",
        "def val2list(val, repeat_time=1):\n",
        "    if isinstance(val, list) or isinstance(val, np.ndarray):\n",
        "        return val\n",
        "    elif isinstance(val, tuple):\n",
        "        return list(val)\n",
        "    else:\n",
        "        return [val for _ in range(repeat_time)]\n",
        "\n",
        "def set_active_subnet(ofa, d=None, e=None, w=None, **kwargs):\n",
        "    depth = val2list(d, len(ofa.BASE_DEPTH_LIST) + 1)\n",
        "    expand_ratio = val2list(e, len(ofa.blocks))\n",
        "    width_mult = val2list(w, len(ofa.BASE_DEPTH_LIST) + 2)\n",
        "    for block, e in zip(ofa.blocks, expand_ratio):\n",
        "        if e is not None:\n",
        "            block.active_expand_ratio = e\n",
        "\n",
        "    if width_mult[0] is not None:\n",
        "        ofa.input_stem[1].conv.active_out_channel = ofa.input_stem[0].active_out_channel = \\\n",
        "            ofa.input_stem[0].out_channel_list[width_mult[0]]\n",
        "    if width_mult[1] is not None:\n",
        "        ofa.input_stem[2].active_out_channel = ofa.input_stem[2].out_channel_list[width_mult[1]]\n",
        "\n",
        "    if depth[0] is not None:\n",
        "        ofa.input_stem_skipping = (depth[0] != max(ofa.depth_list))\n",
        "    for stage_id, (block_idx, d, w) in enumerate(zip(ofa.grouped_block_index, depth[1:], width_mult[2:])):\n",
        "        if d is not None:\n",
        "            ofa.runtime_depth[stage_id] = max(ofa.depth_list) - d\n",
        "        if w is not None:\n",
        "            for idx in block_idx:\n",
        "                ofa.blocks[idx].active_out_channel = ofa.blocks[idx].out_channel_list[w]\n",
        "\n",
        "def set_max_subnet(ofa):\n",
        "    set_active_subnet(ofa, max(ofa.depth_list), max(ofa.expand_ratio_list), len(ofa.width_mult_list) - 1)\n",
        "\n",
        "def get_active_subnet(ofa, preserve_weight=True):\n",
        "    input_stem = [ofa.input_stem[0].get_active_subnet(3, preserve_weight)]\n",
        "    active_out = ofa.input_stem[0].active_out_channel\n",
        "    input_stem_blocks = [(0, active_out)]\n",
        "    \n",
        "    if ofa.input_stem_skipping <= 0:        \n",
        "        input_stem.append(ResidualBlock(\n",
        "            ofa.input_stem[1].conv.get_active_subnet(active_out, preserve_weight),\n",
        "            IdentityLayer(active_out, active_out)\n",
        "        ))\n",
        "        input_stem_blocks += [(1, active_out)]\n",
        "    input_stem.append(ofa.input_stem[2].get_active_subnet(active_out, preserve_weight))\n",
        "    input_channel = ofa.input_stem[2].active_out_channel\n",
        "    input_stem_blocks += [(2, input_channel)]\n",
        " \n",
        "    blocks = []\n",
        "    block_groups = []\n",
        "    block_input_channel = {}\n",
        "    for stage_id, block_idx in enumerate(ofa.grouped_block_index):\n",
        "        depth_param = ofa.runtime_depth[stage_id]\n",
        "        active_idx = block_idx[:len(block_idx) - depth_param]\n",
        "        block_groups+= active_idx\n",
        "        for idx in active_idx:\n",
        "            block_input_channel[idx] = input_channel\n",
        "            blocks.append(ofa.blocks[idx].get_active_subnet(input_channel, preserve_weight))            \n",
        "            input_channel = ofa.blocks[idx].active_out_channel\n",
        "                 \n",
        "    classifier = ofa.classifier.get_active_subnet(input_channel, preserve_weight)\n",
        "\n",
        "    subnet = ResNets(input_stem, blocks, classifier)\n",
        "    subnet.set_bn_param(**ofa.get_bn_param())\n",
        "    subnet.input_stem_blocks = dict(input_stem_blocks)\n",
        "    subnet.block_groups = block_groups\n",
        "    subnet.block_input_channel = block_input_channel\n",
        "    return subnet\n"
      ],
      "id": "mGw3VCBgash7",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtfizHWm16D_"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "def nested_children(m: torch.nn.Module):\n",
        "    children = dict(m.named_children())\n",
        "    output = {}\n",
        "    if children == {}:\n",
        "        return m\n",
        "    else:\n",
        "        for name, child in children.items():\n",
        "            try:\n",
        "                output[name] = nested_children(child)\n",
        "            except TypeError:\n",
        "                output[name] = nested_children(child)\n",
        "    return output\n",
        "\n",
        "def squash_nested_dict(nested_dict, ret_lst={}, prefix='', mod=None):\n",
        "    if nested_dict == {}:\n",
        "        ret_lst[prefix[1:]] = mod\n",
        "        return\n",
        "    for k in nested_dict.keys():\n",
        "        if isinstance(nested_dict[k], dict):\n",
        "            squash_nested_dict(nested_dict[k], ret_lst, prefix+'.'+k)\n",
        "        else:\n",
        "            squash_nested_dict({}, ret_lst, prefix+'.'+k, nested_dict[k])\n",
        "\n",
        "def remap_weight_names(mappings, dict1):\n",
        "    input_stem = mappings['input_stem']\n",
        "    block = mappings['blocks']\n",
        "    map = dict1.copy()\n",
        "    tmp = {}\n",
        "    for i, (input_id, channel) in enumerate(input_stem.items()):\n",
        "        tmp[str(input_id)] = map['input_stem'][str(i)]\n",
        "    \n",
        "    map['input_stem'] = tmp\n",
        "    tmp = {}\n",
        "    for i in map['blocks']:\n",
        "        idx = block[int(i)]\n",
        "        tmp[str(idx)] = map['blocks'][i]\n",
        "    \n",
        "    map['blocks'] = tmp\n",
        "    return map\n",
        "\n",
        "class Quant_Model(nn.Module):\n",
        "    def __init__(self, quat_model, float_model):\n",
        "        super(Quant_Model, self).__init__()\n",
        "        self.input_zero_points = {}\n",
        "        self.input_scales = {}\n",
        "        self.float_model = float_model\n",
        "        self.quant_model = quat_model\n",
        "        self.quant_state_dict = quat_model.state_dict()\n",
        "\n",
        "        layer_names = {}\n",
        "        _layers = nested_children(self.float_model)\n",
        "        squash_nested_dict(_layers, layer_names)\n",
        "        \n",
        "        _quant_layers = nested_children(self.quant_model)\n",
        "        \n",
        "        _remap = remap_weight_names({\n",
        "            'input_stem':self.float_model.input_stem_blocks,\n",
        "            'blocks': self.float_model.block_groups,\n",
        "        }, _layers)\n",
        "\n",
        "        _remap_names = {}\n",
        "        squash_nested_dict(_remap, _remap_names)\n",
        "        \n",
        "        # for l1, l2 in zip(layer_names.keys(), _remap_names.keys()):\n",
        "        #     print(l1, l2)\n",
        "        \n",
        "        self._remapped_layer_names = dict(zip(layer_names.keys(), _remap_names.keys()))\n",
        "\n",
        "        # for i, l in enumerate(list(layer_names.keys())):\n",
        "        #     layer_names[l].register_forward_pre_hook(self.forward_pre_hook(l))\n",
        "        for i, l in enumerate(list(layer_names.keys())):\n",
        "            layer_names[l].register_forward_hook(self.forward_hook(l))\n",
        "\n",
        "    def forward_pre_hook(self, layer_name):\n",
        "        def pre_hook(module, x):\n",
        "            if isinstance(module, nn.Conv2d) or isinstance(module, nn.Identity):\n",
        "                with torch.no_grad():\n",
        "                    quant_model_layer = self._remapped_layer_names[layer_name]\n",
        "                    zero_point = self.quant_state_dict[quant_model_layer+'.zero_point'].float()\n",
        "                    scale = self.quant_state_dict[quant_model_layer+'.scale'].float()\n",
        "                    quant_min = -1.0\n",
        "                    quant_max = 1.0\n",
        "                    # tmp = torch.clamp(torch.round(torch.div(x[0], scale) + zero_point), quant_min, quant_max) - zero_point\n",
        "                    tmp = torch.round(x[0] / scale + zero_point)\n",
        "                    tmp = (tmp - zero_point) * scale\n",
        "                    x = tmp\n",
        "            return x\n",
        "        return pre_hook\n",
        "\n",
        "    def forward_hook(self, layer_name):\n",
        "        def fwd_hook(module, x, y):\n",
        "            if isinstance(module, nn.Conv2d): \n",
        "                with torch.no_grad():\n",
        "                    quant_model_layer = self._remapped_layer_names[layer_name]\n",
        "                    zero_point = self.quant_state_dict[quant_model_layer+'.zero_point'].float()\n",
        "                    scale = self.quant_state_dict[quant_model_layer+'.scale'].float()\n",
        "                    quant_min = -1.0\n",
        "                    quant_max = 1.0\n",
        "                    # tmp = torch.clamp(torch.round(torch.div(x[0], scale) + zero_point), quant_min, quant_max) - zero_point\n",
        "                    tmp = torch.round(y / scale + zero_point)\n",
        "                    tmp = (tmp - zero_point) * scale\n",
        "                    y = tmp\n",
        "            return y\n",
        "        return fwd_hook\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.float_model(x)\n",
        "\n"
      ],
      "id": "FtfizHWm16D_",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOLbEMvy_L_O"
      },
      "source": [
        "\n",
        "set_max_subnet(raw_resnet)\n",
        "max_subnet = get_active_subnet(raw_resnet)\n",
        "max_subnet.eval()\n",
        "max_subnet.qconfig = torch.quantization.get_default_qconfig(config)\n",
        "\n",
        "set_active_subnet(raw_resnet, 0, 0, 0)\n",
        "min_subnet = get_active_subnet(raw_resnet)\n",
        "min_subnet.eval()\n",
        "min_subnet.qconfig = torch.quantization.get_default_qconfig(config)\n",
        "\n",
        "input_fp32 = torch.randn(1, 3, 224, 224, dtype=torch.float32)\n",
        "\n",
        "min_subnet_1 = torch.quantization.prepare(min_subnet)\n",
        "_ = min_subnet_1(input_fp32)\n",
        "quat_min_model = torch.quantization.convert(min_subnet_1)\n",
        "\n",
        "max_subnet_1 = torch.quantization.prepare(max_subnet)\n",
        "_ = max_subnet_1(input_fp32)\n",
        "quat_max_model = torch.quantization.convert(max_subnet_1)\n",
        "\n",
        "# max_subnet.load_state_dict(torch.load('./large_subnet.pth'))\n",
        "\n",
        "fake_quant_model = Quant_Model(quat_max_model, max_subnet)\n",
        "fake_output = fake_quant_model(input_fp32)"
      ],
      "id": "SOLbEMvy_L_O",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00tkyMpU1_bM"
      },
      "source": [
        "ImagenetDataProvider.DEFAULT_PATH = './imagenet-mini'\n",
        "run_config = ImagenetRunConfig(test_batch_size=16, n_worker=20)\n",
        "run_config.data_provider.assign_active_img_size(224)\n",
        "\n",
        "run_manager = RunManager('./tmp/eval_subnet', min_subnet, run_config, init=False)\n",
        "run_manager.reset_running_statistics(net=min_subnet) \n"
      ],
      "id": "00tkyMpU1_bM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfXsXD-Hswtg"
      },
      "source": [
        ""
      ],
      "id": "EfXsXD-Hswtg"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "jdCSc3Q7GHF2",
        "outputId": "5d56818e-6a0e-457f-bfee-3f62b505fbc1"
      },
      "source": [
        "loss, (top1, top5) = run_manager.validate(net=fake_quant_model)\n",
        "print('\\nResults: loss=%.5f,\\t top1=%.3f,\\t top5=%.3f' % (loss, top1, top5))"
      ],
      "id": "jdCSc3Q7GHF2",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validate Epoch #1 :  33%|███▎      | 80/246 [10:30<21:48,  7.88s/it, loss=0.992, top1=78.7, top5=94.3, img_size=224]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-a6c84d9f1ffb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtop1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfake_quant_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nResults: loss=%.5f,\\t top1=%.3f,\\t top5=%.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ofa/imagenet_classification/run_manager/run_manager.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, epoch, is_test, run_str, net, data_loader, no_logs, train_mode)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                     \u001b[0;31m# compute output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                     \u001b[0;31m# measure accuracy and record loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-5e4e2e45e7ea>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ofa/imagenet_classification/networks/resnets.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_avg_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ofa/utils/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    613\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m                 self._forward_hooks.values()):\n\u001b[0;32m--> 893\u001b[0;31m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-5e4e2e45e7ea>\u001b[0m in \u001b[0;36mfwd_hook\u001b[0;34m(module, x, y)\u001b[0m\n\u001b[1;32m    102\u001b[0m                     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mzero_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mzero_point\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfwd_hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOuilXAwGKva"
      },
      "source": [
        "set_max_subnet(raw_resnet)\n",
        "max_subnet = get_active_subnet(raw_resnet)\n",
        "max_subnet.eval()\n",
        "max_subnet.qconfig = torch.quantization.get_default_qconfig(config)\n",
        "# max_subnet.load_state_dict(torch.load('./large_subnet.pth'))\n",
        "loss, (top1, top5) = run_manager.validate(net=max_subnet)\n",
        "print('\\nResults: loss=%.5f,\\t top1=%.3f,\\t top5=%.3f' % (loss, top1, top5))"
      ],
      "id": "pOuilXAwGKva",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFw9ShUySjVj"
      },
      "source": [
        "class OurObserver(torch.quantization.MinMaxObserver):\n",
        "    min_vals: torch.Tensor\n",
        "    max_vals: torch.Tensor\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(OurObserver, self).__init__(qscheme=torch.per_channel_symmetric, dtype=torch.qint8)\n",
        "        self.ch_axis = 0\n",
        "        self.register_buffer('min_vals', torch.tensor([]))\n",
        "        self.register_buffer('max_vals', torch.tensor([]))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        if x.numel() == 0:\n",
        "            return x\n",
        "        if self.min_vals.numel() == 0:\n",
        "            self.min_vals = torch.zeros([*x.shape[0:2]])\n",
        "        if self.max_vals.numel() == 0:\n",
        "            self.max_vals = torch.zeros([*x.shape[0:2]])\n",
        "        min_vals = self.min_vals\n",
        "        max_vals = self.max_vals\n",
        "        x_orig = x.detach()\n",
        "        x_orig = x_orig.to(self.min_vals.dtype)\n",
        "        x_orig = torch.flatten(x_orig, start_dim=-2, end_dim=-1)\n",
        "        min_val_cur, max_val_cur = torch._aminmax(x_orig, -1)\n",
        "        min_vals = torch.min(min_val_cur, self.min_vals)\n",
        "        max_vals = torch.max(max_val_cur, self.max_vals)\n",
        "        self.min_vals.copy_(min_vals)\n",
        "        self.max_vals.copy_(max_vals)\n",
        "        return x\n",
        "    \n",
        "    def calculate_qparams(self):       \n",
        "        scales, zero_point = self._calculate_qparams(self.min_vals, self.max_vals)\n",
        "        print(scales.shape, zero_point.shape)\n",
        "        return scales, zero_point\n"
      ],
      "id": "mFw9ShUySjVj",
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E17KiGPkNbqF",
        "outputId": "8b15cac4-7c02-4484-833b-e6d74b7155a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "source": [
        "min_subnet.eval()\n",
        "min_subnet.qconfig = torch.quantization.QConfig(activation=torch.quantization.PerChannelMinMaxObserver.with_args(ch_axis=0, dtype=torch.qint8, qscheme=torch.per_channel_symmetric), weight=OurObserver.with_args())\n",
        "\n",
        "input_fp32 = torch.randn(1, 3, 224, 224, dtype=torch.float32)\n",
        "min_subnet_1 = torch.quantization.prepare(min_subnet)\n",
        "_ = min_subnet_1(input_fp32)\n",
        "quat_min_model = torch.quantization.convert(min_subnet_1)"
      ],
      "id": "E17KiGPkNbqF",
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([24, 3]) torch.Size([24, 3])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-136-d78ee2694e18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmin_subnet_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_subnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_subnet_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fp32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mquat_min_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_subnet_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/quantization/quantize.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(module, mapping, inplace, remove_qconfig, convert_custom_config_dict)\u001b[0m\n\u001b[1;32m    471\u001b[0m     _convert(\n\u001b[1;32m    472\u001b[0m         \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m         convert_custom_config_dict=convert_custom_config_dict)\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mremove_qconfig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0m_remove_qconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/quantization/quantize.py\u001b[0m in \u001b[0;36m_convert\u001b[0;34m(module, mapping, inplace, convert_custom_config_dict)\u001b[0m\n\u001b[1;32m    506\u001b[0m            \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcustom_module_class_mapping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             _convert(mod, mapping, True,  # inplace\n\u001b[0;32m--> 508\u001b[0;31m                      custom_module_class_mapping)\n\u001b[0m\u001b[1;32m    509\u001b[0m         \u001b[0mreassign\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswap_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_module_class_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/quantization/quantize.py\u001b[0m in \u001b[0;36m_convert\u001b[0;34m(module, mapping, inplace, convert_custom_config_dict)\u001b[0m\n\u001b[1;32m    506\u001b[0m            \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcustom_module_class_mapping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             _convert(mod, mapping, True,  # inplace\n\u001b[0;32m--> 508\u001b[0;31m                      custom_module_class_mapping)\n\u001b[0m\u001b[1;32m    509\u001b[0m         \u001b[0mreassign\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswap_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_module_class_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/quantization/quantize.py\u001b[0m in \u001b[0;36m_convert\u001b[0;34m(module, mapping, inplace, convert_custom_config_dict)\u001b[0m\n\u001b[1;32m    507\u001b[0m             _convert(mod, mapping, True,  # inplace\n\u001b[1;32m    508\u001b[0m                      custom_module_class_mapping)\n\u001b[0;32m--> 509\u001b[0;31m         \u001b[0mreassign\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswap_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_module_class_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreassign\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/quantization/quantize.py\u001b[0m in \u001b[0;36mswap_module\u001b[0;34m(mod, mapping, custom_module_class_mapping)\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0mswapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mnew_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m             \u001b[0mswapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/quantized/modules/conv.py\u001b[0m in \u001b[0;36mfrom_float\u001b[0;34m(cls, mod)\u001b[0m\n\u001b[1;32m    416\u001b[0m               \u001b[0mutilities\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \"\"\"\n\u001b[0;32m--> 418\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ConvNd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/quantized/modules/conv.py\u001b[0m in \u001b[0;36mfrom_float\u001b[0;34m(cls, mod)\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mweight_post_process\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_qconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_post_process\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_post_process\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/quantized/modules/conv.py\u001b[0m in \u001b[0;36mget_qconv\u001b[0;34m(cls, mod, activation_post_process, weight_post_process)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mweight_post_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqint8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;34m'Weight observer must have a dtype of qint8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mqweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_quantize_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_post_process\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;31m# the __init__ call used is the one from derived classes and not the one from _ConvNd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         qconv = cls(mod.in_channels, mod.out_channels, mod.kernel_size,  # type: ignore[call-arg]\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/quantized/modules/utils.py\u001b[0m in \u001b[0;36m_quantize_weight\u001b[0;34m(float_wt, observer)\u001b[0m\n\u001b[1;32m     14\u001b[0m         qweight = torch.quantize_per_channel(\n\u001b[1;32m     15\u001b[0m             \u001b[0mfloat_wt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             wt_scale.to(torch.double), wt_zp.to(torch.int64), wt_axis, torch.qint8)\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mobserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqscheme\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mper_channel_affine_float_qparams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         qweight = torch.quantize_per_channel(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: scale tensor must have dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AtIhR5bUFuy"
      },
      "source": [
        ""
      ],
      "id": "_AtIhR5bUFuy",
      "execution_count": null,
      "outputs": []
    }
  ]
}