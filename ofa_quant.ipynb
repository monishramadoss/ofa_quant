{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "ofa_quant.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monishramadoss/ofa_quant/blob/main/ofa_quant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BesMFL3fVdax",
        "outputId": "446e007e-5e66-47d7-d25b-ebddf7e2ab5e"
      },
      "source": [
        "!pip install torch==1.4.0 torchvision==0.5.0\n",
        "!pip install ofa\n",
        "! git clone https://github.com/seshuad/IMagenet\n",
        "! ls 'IMagenet/tiny-imagenet-200/'"
      ],
      "id": "BesMFL3fVdax",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.4.0\n",
            "  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4 MB 6.7 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.5.0\n",
            "  Downloading torchvision-0.5.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 44.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0) (1.15.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0) (7.1.2)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.4.0 torchvision-0.5.0\n",
            "Collecting ofa\n",
            "  Downloading ofa-0.1.0.post202111231444-py3-none-any.whl (102 kB)\n",
            "\u001b[K     |████████████████████████████████| 102 kB 9.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from ofa) (1.4.0)\n",
            "Installing collected packages: ofa\n",
            "Successfully installed ofa-0.1.0.post202111231444\n",
            "Cloning into 'IMagenet'...\n",
            "remote: Enumerating objects: 120594, done.\u001b[K\n",
            "remote: Total 120594 (delta 0), reused 0 (delta 0), pack-reused 120594\u001b[K\n",
            "Receiving objects: 100% (120594/120594), 212.68 MiB | 28.56 MiB/s, done.\n",
            "Resolving deltas: 100% (1115/1115), done.\n",
            "Checking out files: 100% (120206/120206), done.\n",
            "test  train  val  wnids.txt  words.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp77tl4giVWJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0238cf6d-0f79-405e-ace2-b3351f502d38"
      },
      "source": [
        "import time\n",
        "import skimage.io as nd\n",
        "import numpy as np\n",
        "import torch\n",
        "import skimage.color\n",
        "\n",
        "\n",
        "path = 'IMagenet/tiny-imagenet-200/'\n",
        "\n",
        "def get_id_dictionary():\n",
        "    id_dict = {}\n",
        "    for i, line in enumerate(open( path + 'wnids.txt', 'r')):\n",
        "        id_dict[line.replace('\\n', '')] = i\n",
        "    return id_dict\n",
        "  \n",
        "def get_class_to_id_dict():\n",
        "    id_dict = get_id_dictionary()\n",
        "    all_classes = {}\n",
        "    result = {}\n",
        "    for i, line in enumerate(open( path + 'words.txt', 'r')):\n",
        "        n_id, word = line.split('\\t')[:2]\n",
        "        all_classes[n_id] = word\n",
        "    for key, value in id_dict.items():\n",
        "        result[value] = (key, all_classes[key])      \n",
        "    return result\n",
        "\n",
        "def get_data(id_dict):\n",
        "    print('starting loading data')\n",
        "    train_data, test_data = [], []\n",
        "    train_labels, test_labels = [], []\n",
        "    t = time.time()\n",
        "    for key, value in id_dict.items():\n",
        "        train_data += [nd.imread( path + 'train/{}/images/{}_{}.JPEG'.format(key, key, str(i)), as_gray=False ) for i in range(500)]\n",
        "        train_labels_ = np.array([[0]*200]*500)\n",
        "        train_labels_[:, value] = 1\n",
        "        train_labels += train_labels_.tolist()\n",
        "\n",
        "    for line in open( path + 'val/val_annotations.txt'):\n",
        "        img_name, class_id = line.split('\\t')[:2]\n",
        "        test_data += [nd.imread( path + 'val/images/{}'.format(img_name), as_gray=False)]\n",
        "        \n",
        "        # test_data.append(test_data_)\n",
        "        test_labels_ = np.array([[0]*200])\n",
        "        test_labels_[0, id_dict[class_id]] = 1\n",
        "        test_labels += test_labels_.tolist()\n",
        "\n",
        "    for i in range(len(test_data)):\n",
        "        if test_data[i].ndim == 2:\n",
        "            test_data[i] = skimage.color.gray2rgb(test_data[i])\n",
        "\n",
        "    for i in range(len(train_data)):\n",
        "        if train_data[i].ndim == 2:\n",
        "            train_data[i] = skimage.color.gray2rgb(train_data[i])\n",
        "\n",
        "    print('finished loading data, in {} seconds'.format(time.time() - t))\n",
        "    test = np.array(test_data), np.array(test_labels)  \n",
        "    return np.array(train_data), np.array(train_labels), *test\n",
        "\n",
        "def evaluate(model, data, target):\n",
        "    model.eval()  # set model in eval mode\n",
        "    total_time = 0\n",
        "    num_correct = 0  # total 1000\n",
        "    with torch.no_grad():\n",
        "        for image, target in zip(data, target):\n",
        "            # print(data[0].shape)\n",
        "            start = time.time()\n",
        "            result = model(image)\n",
        "            total_time += time.time() - start\n",
        "            \n",
        "            prediction = idx2label[int(result[0].sort()[1][-1:])]\n",
        "            if target == prediction:\n",
        "                num_correct += 1\n",
        "    \n",
        "    inference_time = total_time / len(data)\n",
        "    accuracy = num_correct / len(data)\n",
        "    return inference_time, accuracy\n",
        "\n",
        "train_data, train_labels, test_data, train_labels = get_data(get_id_dictionary())"
      ],
      "id": "Kp77tl4giVWJ",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting loading data\n",
            "finished loading data, in 50.535794496536255 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut9A9EV1bsDe",
        "outputId": "57dc70d4-31fe-4323-c6f6-934894b78659"
      },
      "source": [
        "print(train_data.shape, train_labels.shape)"
      ],
      "id": "ut9A9EV1bsDe",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100000, 64, 64, 3) (100000, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98SBhCpxVfeu",
        "outputId": "50fbb76c-2331-4cfa-eafa-e19e9b99cbd0"
      },
      "source": [
        "import copy\n",
        "import torch\n",
        "from ofa.model_zoo import ofa_net\n",
        "from ofa.imagenet_classification.data_providers.imagenet import ImagenetDataProvider\n",
        "# from ofa.imagenet_classification.run_manager import ImagenetRunConfig, RunManager\n",
        "\n",
        "raw_resnet = ofa_net('ofa_resnet50', pretrained=True)\n",
        "raw_resnet.set_max_net()\n",
        "max_subnet = raw_resnet.get_active_subnet(preserve_weight=True)\n",
        "raw_resnet.set_active_subnet(d=0, w=0, e=0)\n",
        "min_subnet = raw_resnet.get_active_subnet(preserve_weight=True)\n",
        "\n",
        "\n",
        "# ImagenetDataProvider.DEFAULT_PATH = path\n",
        "# run_config = ImagenetRunConfig(test_batch_size=16, n_worker=20)\n",
        "# run_config.data_provider.assign_active_img_size(64)\n",
        "\n",
        "\n",
        "# run_manager = RunManager('./tmp/eval_subnet', min_subnet, run_config, init=False)\n",
        "# run_manager.reset_running_statistics(net=min_subnet)"
      ],
      "id": "98SBhCpxVfeu",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://hanlab.mit.edu/files/OnceForAll/ofa_nets/ofa_resnet50_d=0+1+2_e=0.2+0.25+0.35_w=0.65+0.8+1.0\" to .torch/ofa_nets/ofa_resnet50_d=0+1+2_e=0.2+0.25+0.35_w=0.65+0.8+1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X2FmwwSqbGx"
      },
      "source": [
        "# loss, (top1, top5) = run_manager.validate(net=max_subnet, is_test=True)\n",
        "# print('\\nResults: loss=%.5f,\\t top1=%.1f,\\t top5=%.1f' % (loss, top1, top5))\n",
        "# loss, (top1, top5) = run_manager.validate(net=min_subnet, is_test=True)\n",
        "# print('\\nResults: loss=%.5f,\\t top1=%.1f,\\t top5=%.1f' % (loss, top1, top5))"
      ],
      "id": "0X2FmwwSqbGx",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGw3VCBgash7"
      },
      "source": [
        "from ofa.imagenet_classification.networks import ResNets\n",
        "from ofa.utils.layers import IdentityLayer, ResidualBlock\n",
        "\n",
        "def val2list(val, repeat_time=1):\n",
        "    if isinstance(val, list) or isinstance(val, np.ndarray):\n",
        "        return val\n",
        "    elif isinstance(val, tuple):\n",
        "        return list(val)\n",
        "    else:\n",
        "        return [val for _ in range(repeat_time)]\n",
        "\n",
        "def set_active_subnet(ofa, d=None, e=None, w=None, **kwargs):\n",
        "    depth = val2list(d, len(ofa.BASE_DEPTH_LIST) + 1)\n",
        "    expand_ratio = val2list(e, len(ofa.blocks))\n",
        "    width_mult = val2list(w, len(ofa.BASE_DEPTH_LIST) + 2)\n",
        "    for block, e in zip(ofa.blocks, expand_ratio):\n",
        "        if e is not None:\n",
        "            block.active_expand_ratio = e\n",
        "\n",
        "    if width_mult[0] is not None:\n",
        "        ofa.input_stem[1].conv.active_out_channel = ofa.input_stem[0].active_out_channel = \\\n",
        "            ofa.input_stem[0].out_channel_list[width_mult[0]]\n",
        "    if width_mult[1] is not None:\n",
        "        ofa.input_stem[2].active_out_channel = ofa.input_stem[2].out_channel_list[width_mult[1]]\n",
        "\n",
        "    if depth[0] is not None:\n",
        "        ofa.input_stem_skipping = (depth[0] != max(ofa.depth_list))\n",
        "    for stage_id, (block_idx, d, w) in enumerate(zip(ofa.grouped_block_index, depth[1:], width_mult[2:])):\n",
        "        if d is not None:\n",
        "            ofa.runtime_depth[stage_id] = max(ofa.depth_list) - d\n",
        "        if w is not None:\n",
        "            for idx in block_idx:\n",
        "                ofa.blocks[idx].active_out_channel = ofa.blocks[idx].out_channel_list[w]\n",
        "\n",
        "def set_max_subnet(ofa):\n",
        "    set_active_subnet(ofa, max(ofa.depth_list), max(ofa.expand_ratio_list), len(ofa.width_mult_list) - 1)\n",
        "\n",
        "def get_active_subnet(ofa, preserve_weight=True):\n",
        "    input_stem = [ofa.input_stem[0].get_active_subnet(3, preserve_weight)]\n",
        "    active_out = ofa.input_stem[0].active_out_channel\n",
        "    input_stem_blocks = [0]\n",
        "\n",
        "    if ofa.input_stem_skipping <= 0:        \n",
        "        input_stem.append(ResidualBlock(\n",
        "            ofa.input_stem[1].conv.get_active_subnet(active_out, preserve_weight),\n",
        "            IdentityLayer(active_out, active_out)\n",
        "        ))\n",
        "        input_stem_blocks += [1]\n",
        "    input_stem_blocks += [2]\n",
        "    input_stem.append(ofa.input_stem[2].get_active_subnet(active_out, preserve_weight))\n",
        "    input_channel = ofa.input_stem[2].active_out_channel\n",
        "\n",
        "    blocks = []\n",
        "    block_groups = []\n",
        "    for stage_id, block_idx in enumerate(ofa.grouped_block_index):\n",
        "        depth_param = ofa.runtime_depth[stage_id]\n",
        "        active_idx = block_idx[:len(block_idx) - depth_param]\n",
        "        block_groups.append(active_idx)\n",
        "        for idx in active_idx:\n",
        "            blocks.append(ofa.blocks[idx].get_active_subnet(input_channel, preserve_weight))\n",
        "            input_channel = ofa.blocks[idx].active_out_channel\n",
        "    classifier = ofa.classifier.get_active_subnet(input_channel, preserve_weight)\n",
        "\n",
        "    subnet = ResNets(input_stem, blocks, classifier)\n",
        "    subnet.set_bn_param(**ofa.get_bn_param())\n",
        "    subnet.input_stem_blocks = input_stem_blocks\n",
        "    subnet.block_groups = block_groups\n",
        "    return subnet\n"
      ],
      "id": "mGw3VCBgash7",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu6ypVBm9IsY"
      },
      "source": [
        "# run_manager_quant = RunManager('./tmp/eval', min_subnet, run_config=run_config, init=False, no_gpu=True)"
      ],
      "id": "Mu6ypVBm9IsY",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjVCLHzLawE7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8ca3939-6998-4c3d-eeb6-4d1b0c0520f2"
      },
      "source": [
        "input_fp32 = torch.randn(1, 3, 224, 224)\n",
        "\n",
        "set_max_subnet(raw_resnet)\n",
        "max_subnet = get_active_subnet(raw_resnet)\n",
        "\n",
        "max_subnet.eval()\n",
        "config = 'fbgemm'\n",
        "max_subnet.qconfig = torch.quantization.get_default_qconfig(config)\n",
        "max_subnet_1 = torch.quantization.prepare(max_subnet)\n",
        "_ = max_subnet_1(input_fp32)\n",
        "quat_max_model = torch.quantization.convert(max_subnet_1)\n",
        "\n",
        "\n"
      ],
      "id": "LjVCLHzLawE7",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvLayer(\n",
              "  (conv): QuantizedConv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), scale=0.35585781931877136, zero_point=62, padding=(1, 1), bias=False)\n",
              "  (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (act): QuantizedReLU(inplace=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brYzf6rl0bii"
      },
      "source": [
        "temp = dict({('blocks.0.conv1.conv.scale', 0.3034),\n",
        " ('blocks.0.conv2.conv.scale', 0.3898),\n",
        " ('blocks.0.conv3.conv.scale', 0.3047),\n",
        " ('blocks.0.downsample.conv.scale', 0.4795),\n",
        " ('blocks.1.conv1.conv.scale', 0.2099),\n",
        " ('blocks.1.conv2.conv.scale', 0.2258),\n",
        " ('blocks.1.conv3.conv.scale', 0.3333),\n",
        " ('blocks.10.conv1.conv.scale', 0.2817),\n",
        " ('blocks.10.conv2.conv.scale', 0.3093),\n",
        " ('blocks.10.conv3.conv.scale', 0.2963),\n",
        " ('blocks.11.conv1.conv.scale', 0.6109),\n",
        " ('blocks.11.conv2.conv.scale', 0.5077),\n",
        " ('blocks.11.conv3.conv.scale', 0.3028),\n",
        " ('blocks.12.conv1.conv.scale', 0.2717),\n",
        " ('blocks.12.conv2.conv.scale', 0.2179),\n",
        " ('blocks.12.conv3.conv.scale', 0.1239),\n",
        " ('blocks.13.conv1.conv.scale', 0.2204),\n",
        " ('blocks.13.conv2.conv.scale', 0.4078),\n",
        " ('blocks.13.conv3.conv.scale', 0.3996),\n",
        " ('blocks.14.conv1.conv.scale', 0.2612),\n",
        " ('blocks.14.conv2.conv.scale', 0.2186),\n",
        " ('blocks.14.conv3.conv.scale', 0.3380),\n",
        " ('blocks.14.downsample.conv.scale', 0.5858),\n",
        " ('blocks.15.conv1.conv.scale', 0.7731),\n",
        " ('blocks.15.conv2.conv.scale', 0.4752),\n",
        " ('blocks.15.conv3.conv.scale', 0.5223),\n",
        " ('blocks.16.conv1.conv.scale', 0.3974),\n",
        " ('blocks.16.conv2.conv.scale', 0.2534),\n",
        " ('blocks.16.conv3.conv.scale', 0.3723),\n",
        " ('blocks.17.conv1.conv.scale', 0.2302),\n",
        " ('blocks.17.conv2.conv.scale', 0.2933),\n",
        " ('blocks.17.conv3.conv.scale', 0.3231),\n",
        " ('blocks.2.conv1.conv.scale', 0.1517),\n",
        " ('blocks.2.conv2.conv.scale', 0.1271),\n",
        " ('blocks.2.conv3.conv.scale', 0.1200),\n",
        " ('blocks.3.conv1.conv.scale', 0.1193),\n",
        " ('blocks.3.conv2.conv.scale', 0.1338),\n",
        " ('blocks.3.conv3.conv.scale', 0.0980),\n",
        " ('blocks.4.conv1.conv.scale', 0.2068),\n",
        " ('blocks.4.conv2.conv.scale', 0.3214),\n",
        " ('blocks.4.conv3.conv.scale', 0.4915),\n",
        " ('blocks.4.downsample.conv.scale', 0.2356),\n",
        " ('blocks.5.conv1.conv.scale', 0.1636),\n",
        " ('blocks.5.conv2.conv.scale', 0.3325),\n",
        " ('blocks.5.conv3.conv.scale', 0.3767),\n",
        " ('blocks.6.conv1.conv.scale', 0.2506),\n",
        " ('blocks.6.conv2.conv.scale', 0.2422),\n",
        " ('blocks.6.conv3.conv.scale', 0.1694),\n",
        " ('blocks.7.conv1.conv.scale', 0.2284),\n",
        " ('blocks.7.conv2.conv.scale', 0.3655),\n",
        " ('blocks.7.conv3.conv.scale', 0.3437),\n",
        " ('blocks.8.conv1.conv.scale', 0.3289),\n",
        " ('blocks.8.conv2.conv.scale', 0.3125),\n",
        " ('blocks.8.conv3.conv.scale', 0.3898),\n",
        " ('blocks.8.downsample.conv.scale', 0.5282),\n",
        " ('blocks.9.conv1.conv.scale', 0.3315),\n",
        " ('blocks.9.conv2.conv.scale', 0.3270),\n",
        " ('blocks.9.conv3.conv.scale', 0.2874),\n",
        " ('input_stem.0.conv.scale', 0.6389),\n",
        " ('input_stem.1.conv.conv.scale', 0.5264),\n",
        " ('input_stem.2.conv.scale', 0.5124)})"
      ],
      "id": "brYzf6rl0bii",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtfizHWm16D_",
        "outputId": "f1108448-10ee-4c3a-e3fb-d8aa08f92c70"
      },
      "source": [
        "import torch.nn as nn\n",
        "def nested_children(m: torch.nn.Module):\n",
        "    children = dict(m.named_children())\n",
        "    output = {}\n",
        "    if children == {}:\n",
        "        # if module has no children; m is last child! :O\n",
        "        return m\n",
        "    else:\n",
        "        # look for children from children... to the last child!\n",
        "        for name, child in children.items():\n",
        "            try:\n",
        "                output[name] = nested_children(child)\n",
        "            except TypeError:\n",
        "                output[name] = nested_children(child)\n",
        "    return output\n",
        "\n",
        "def squash_nested_dict(nested_dict, ret_lst={}, prefix='', mod=None):\n",
        "    if nested_dict == {}:\n",
        "        ret_lst[prefix[1:]] = mod\n",
        "        return\n",
        "    for k in nested_dict.keys():\n",
        "        if isinstance(nested_dict[k], dict):\n",
        "            squash_nested_dict(nested_dict[k], ret_lst, prefix+'.'+k)\n",
        "        else:\n",
        "            squash_nested_dict({}, ret_lst, prefix+'.'+k, nested_dict[k])\n",
        "\n",
        "\n",
        "\n",
        "class Quant_Model(nn.Module):\n",
        "    def __init__(self, quat_model, float_model):\n",
        "        super(Quant_Model, self).__init__()\n",
        "        self.input_zero_points = {}\n",
        "        self.input_scales = {}\n",
        "        self.float_model = float_model\n",
        "        self.quat_model = quat_model\n",
        "        self.quant_state_dict = quat_model.state_dict()\n",
        "\n",
        "        layer_names = {}\n",
        "        named_layers = nested_children(self.float_model)\n",
        "        squash_nested_dict(named_layers, layer_names)\n",
        "        \n",
        "        for i, l in enumerate(list(layer_names.keys())):\n",
        "            layer_names[l].register_forward_pre_hook(self.forward_pre_hook(l))\n",
        "\n",
        "    def forward_pre_hook(self, layer_name):\n",
        "        def pre_hook(module, x):\n",
        "            if isinstance(module, nn.Conv2d) or isinstance(module, nn.Identity):\n",
        "                with torch.no_grad():\n",
        "                    zero_point = self.quant_state_dict[layer_name+'.zero_point'].float()\n",
        "                    scale = self.quant_state_dict[layer_name+'.scale'].float()\n",
        "                    quant_min = 0.0\n",
        "                    quant_max = 1.0\n",
        "                    tmp = torch.clamp(torch.round(torch.div(x[0], scale) + zero_point), quant_min, quant_max) - zero_point\n",
        "                    x = tmp*scale\n",
        "            return x\n",
        "        return pre_hook\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.float_model(x)\n",
        "\n",
        "\n",
        "set_active_subnet(raw_resnet, 0, 0, 0)\n",
        "min_subnet = get_active_subnet(raw_resnet)\n",
        "min_subnet.eval()\n",
        "min_subnet.qconfig = torch.quantization.get_default_qconfig(config)\n",
        "\n",
        "input_fp32 = torch.randn(1, 3, 224, 224, dtype=torch.float32)\n",
        "min_subnet_1 = torch.quantization.prepare(min_subnet)\n",
        "\n",
        "_ = min_subnet_1(input_fp32)\n",
        "quat_min_model = torch.quantization.convert(min_subnet_1)\n",
        "\n",
        "fake_quant_model = Quant_Model(quat_min_model, min_subnet)\n",
        "fake_output = fake_quant_model(input_fp32)\n",
        "print(fake_output)"
      ],
      "id": "FtfizHWm16D_",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-2.9306e+02, -6.4418e+00, -5.3657e+01, -2.2284e+01,  2.2735e+02,\n",
            "         -1.1329e+02,  4.8487e+01,  5.6451e+01,  1.7572e+02,  3.6831e+01,\n",
            "         -4.4456e+01, -8.1882e+01,  2.7150e+01,  5.7271e+01, -1.7678e+01,\n",
            "         -7.3381e+01, -3.7374e+01, -4.1221e+01, -2.2437e+01, -4.5825e+01,\n",
            "         -1.1655e+02,  2.2238e+01, -2.1023e+02,  3.3650e+01,  6.6236e+01,\n",
            "         -6.9066e+01, -5.9876e+01, -4.0418e+01, -2.2419e+01, -1.0336e+02,\n",
            "          1.9451e+02, -9.6390e+01,  5.4402e+01, -5.4740e+01, -5.9053e+01,\n",
            "          6.0623e+01,  1.3135e+02,  7.9664e+01, -1.6394e+02,  1.1328e+02,\n",
            "         -4.9874e+01,  6.3055e+01,  5.7795e+01,  1.4287e+02,  7.2237e+01,\n",
            "         -6.0681e+00, -4.6383e+01,  8.5416e+01,  1.0007e+02, -2.3468e+01,\n",
            "          1.1398e+02,  1.9358e+01, -1.0284e+02, -5.4639e+01,  1.5209e+00,\n",
            "         -1.4771e+02, -1.5485e+02,  8.2363e+01,  3.2800e+01, -6.5999e+01,\n",
            "         -8.1575e+01, -1.2488e+02,  1.2206e+02,  7.5755e+01, -9.8413e+01,\n",
            "          9.9465e+01, -1.2350e+02, -3.5494e+00, -1.7935e+02, -9.8731e+01,\n",
            "         -3.3372e+01, -1.0700e+00, -1.2548e+02, -4.5603e+01, -6.3847e+00,\n",
            "         -7.5832e+01, -1.8837e+01,  2.7982e+01, -9.5464e+00, -3.0689e+01,\n",
            "          4.3654e+01,  3.4669e+01,  5.0507e+01, -4.0400e+01,  1.5170e+02,\n",
            "          5.1921e+01,  6.3300e+01, -2.0143e+02, -7.6139e+01, -1.0588e+02,\n",
            "         -2.7759e+00, -1.2049e+02,  6.9771e+01, -9.0410e+01, -1.6236e+01,\n",
            "         -1.6200e+02, -1.4890e+02,  1.1521e+01,  5.6921e+01,  3.7689e+01,\n",
            "         -4.8394e+01,  5.1096e+01,  5.9826e+01, -1.3053e+02,  1.7166e+02,\n",
            "         -7.2528e+01,  4.3641e+01, -1.1332e+01, -8.0388e+01,  2.9851e+01,\n",
            "         -6.0696e+01, -5.6998e+01,  9.4751e+01,  1.0495e+02,  3.8285e+01,\n",
            "         -7.7269e+01,  2.4110e+01, -1.1362e+02,  2.5708e+01,  1.1624e+02,\n",
            "          1.6965e+02,  5.0460e+01, -1.3919e+02,  1.5397e+01,  2.1070e+02,\n",
            "          5.1253e+01, -7.5244e+00, -9.5491e+01, -3.2808e+01, -1.3366e+02,\n",
            "         -1.3750e+02, -1.8395e+02, -2.0286e+02,  6.8390e+01, -5.7704e+00,\n",
            "         -1.8422e+01,  2.5907e+01,  7.0288e+01, -1.1120e+01, -3.4303e+01,\n",
            "         -2.7920e+01,  6.6897e+01,  3.3283e+01, -1.5769e+01,  4.7540e+00,\n",
            "         -9.1448e+01,  2.2112e+01, -6.6597e+01, -1.7059e+01, -1.9785e+02,\n",
            "          7.2823e+01,  5.8748e+01, -1.0478e+02, -9.6826e+01,  1.7385e+01,\n",
            "          6.4356e+01, -8.6530e+01, -1.1308e+02, -1.0478e+02,  3.2274e+01,\n",
            "          3.2968e+01,  2.6254e+00, -2.2181e+02, -1.0519e+01,  9.4491e+01,\n",
            "         -1.4216e+01, -1.1304e+02, -5.9836e+01,  1.5611e+02, -7.9023e+01,\n",
            "         -1.1710e+01, -5.9051e+01, -5.6822e+01, -8.0122e+01,  1.6975e+01,\n",
            "         -6.7364e+01,  1.4789e+02, -5.3624e+01,  9.0128e+01,  2.5911e+00,\n",
            "         -5.2097e+01, -7.0840e+01, -3.0358e+01,  7.8902e-01, -1.1323e+02,\n",
            "          6.4418e+01, -5.9765e+01,  2.8825e+01, -1.4022e+02, -2.0315e+02,\n",
            "         -2.4321e+02, -6.8961e+01,  6.0746e+01, -2.8990e+01, -5.7356e+01,\n",
            "         -6.4847e+01,  1.1331e+02, -1.2242e+01,  1.1504e+01, -1.0048e+01,\n",
            "         -1.5029e+02, -3.3837e+01,  9.2390e+01, -8.4410e+01,  3.6965e+01,\n",
            "          9.5599e+01, -3.6149e+01, -1.1679e+02, -9.9973e+01,  2.0320e+01,\n",
            "          1.0624e+01, -5.1667e+01,  3.1434e+01, -4.3862e+01, -5.6814e+00,\n",
            "         -5.6022e+01,  2.6149e+01, -6.0574e+01, -1.0598e+02,  7.2612e+01,\n",
            "         -1.1283e+02, -9.9998e+01,  6.6654e+01,  4.4476e+01,  1.7634e+01,\n",
            "         -3.9774e+01, -8.8999e+01, -8.1084e+01, -3.3663e+01,  5.8863e+01,\n",
            "         -1.0337e+02,  6.0899e+00, -9.3775e+00, -1.0490e+02, -1.4297e+02,\n",
            "         -4.5348e+01,  3.6196e+01,  3.1176e+01, -1.0947e+01, -5.2583e+01,\n",
            "         -7.4655e+01, -1.1324e+02,  6.6224e+01, -1.0659e+02,  9.7945e+01,\n",
            "          1.9589e+01, -1.3026e+01,  2.4851e+01, -4.3458e+01, -1.8192e+01,\n",
            "         -7.6507e+01, -4.9682e+01, -9.4779e+01, -9.0284e+01,  2.1932e+01,\n",
            "         -1.0356e+01,  8.8374e+01, -1.6231e+01, -1.1337e+02,  1.5397e+01,\n",
            "          1.7801e+01, -3.6176e+01,  9.9420e+01, -9.4269e+01,  6.5295e+01,\n",
            "          4.7543e+01,  4.9526e+01,  5.0539e+01,  1.2816e+02, -4.1041e+01,\n",
            "         -1.6839e+02, -8.9871e+00, -4.0026e+00, -3.6742e+01,  1.0642e+02,\n",
            "         -1.2719e+02, -1.8536e+02, -3.9951e+01, -2.1573e+02, -1.2151e+02,\n",
            "         -1.7628e+01, -1.8598e+01,  7.6278e+01, -4.7711e+01, -1.2611e+01,\n",
            "          2.7234e+00,  5.1110e+01,  8.4163e+01, -1.6968e+01, -8.9267e+01,\n",
            "         -1.0918e+01,  7.9241e+01,  3.0642e+01, -2.3126e+01, -9.7862e+00,\n",
            "          9.8679e+01, -1.3488e+02,  6.2676e+01, -2.5731e+01,  3.5321e+01,\n",
            "         -5.0051e+01,  2.0444e+01, -4.1732e+01,  1.5615e+01, -7.0503e+01,\n",
            "          4.3229e+01, -4.6498e+01,  7.0747e+01, -7.2249e+00, -9.2129e+01,\n",
            "          1.5977e+02, -3.0533e+00,  1.0038e+02, -1.5133e+01, -8.7037e+00,\n",
            "          5.9290e+01, -4.1664e+01, -1.1182e+01, -1.8428e+02, -6.8188e+01,\n",
            "          1.1367e+01, -2.4598e+01, -1.5780e+01, -9.4327e+01, -1.0436e+02,\n",
            "         -7.1398e+01, -1.2022e+02,  1.4568e+02,  1.0201e+02,  1.5254e+01,\n",
            "          2.1634e+02,  6.6991e+01,  8.9345e+01, -1.6285e+02,  1.2110e+02,\n",
            "          1.7342e+01,  1.5531e+01, -3.8301e+00, -1.2302e+02, -3.4711e+01,\n",
            "         -8.1295e+00,  4.3396e+01,  6.2776e+01,  6.2961e+01, -2.5061e+01,\n",
            "          1.5419e+02,  1.0675e+02, -4.9971e+01,  2.0110e+02,  1.6616e+02,\n",
            "          1.9800e+02, -5.1676e+01,  2.6796e+01,  1.0681e+02,  1.7019e+02,\n",
            "          1.9422e+02, -2.7959e+01, -1.1686e+01,  5.8584e+01, -1.8779e+02,\n",
            "          1.1785e+01, -6.5177e+01, -5.9911e+01, -4.4993e+01,  3.7998e+01,\n",
            "          2.9384e+01,  8.5843e+01,  1.1104e+02,  7.0764e+01,  1.3263e+00,\n",
            "         -1.3288e+02, -5.7638e+01,  6.6364e+00,  1.9154e+01, -5.9019e+00,\n",
            "         -1.2892e+01, -4.6382e+01, -2.6039e+01, -8.8049e+01, -1.0545e+02,\n",
            "         -1.1480e+02,  3.9663e+01, -3.6061e+01, -4.6688e+01,  1.4396e+01,\n",
            "          8.4791e+01, -5.0017e+01, -8.4505e+01, -1.0015e+02, -1.9762e+02,\n",
            "          1.0294e+02,  4.6723e+00, -1.2509e+02, -2.0062e+02, -1.7933e+02,\n",
            "         -1.0817e+02, -6.9261e+01, -3.1845e+01,  4.2132e+01, -2.8720e+01,\n",
            "         -6.2391e+01,  1.4215e+02,  2.5071e+01, -2.7404e+01, -2.4872e+01,\n",
            "          1.5240e+01, -1.1277e+02, -6.5986e+01,  5.2168e+01, -1.2217e+01,\n",
            "          9.8764e-01,  1.1797e+02,  1.6469e+02, -5.4525e+01,  2.5328e+02,\n",
            "          5.6470e+01, -8.8496e+01,  1.7548e+00, -5.7751e+01,  2.9308e+01,\n",
            "          8.4118e+01,  1.4383e+02, -1.9204e+02, -2.2705e+02, -2.1285e+02,\n",
            "          1.5312e+02,  8.0517e+00,  1.7863e+02,  1.2616e+02, -1.7269e+02,\n",
            "         -3.1787e+02, -4.0526e+01,  1.8916e+01, -1.8278e+02, -1.3388e+02,\n",
            "          5.5637e+01, -1.0185e+02,  1.2265e+02, -6.8396e+01, -8.4648e+01,\n",
            "         -4.1963e+01, -1.4573e+02,  5.8941e+01, -7.4798e+01, -2.0628e+02,\n",
            "         -2.1910e+02,  1.3782e+02,  1.0680e+02, -1.6244e+00,  3.8652e+01,\n",
            "         -2.4089e+01,  1.6131e+02,  6.7399e+01,  1.1594e+02,  5.4677e+01,\n",
            "         -2.1885e+02, -5.3879e+01,  2.0159e+02,  2.6127e+02, -1.5979e+02,\n",
            "          2.1883e+02, -2.1377e+01,  1.4854e+02,  2.0562e+02,  9.5729e+01,\n",
            "         -1.3843e+00, -9.9119e+00, -1.4561e+02, -7.3116e+01,  5.9478e+01,\n",
            "          3.8885e+01,  2.3391e+01,  2.3932e+01, -7.2651e+01,  6.3079e+00,\n",
            "         -2.0271e+02, -6.7124e+01,  1.0818e+02,  2.9277e+02, -8.6497e-01,\n",
            "          8.4284e+01,  6.5692e+01,  2.4398e+02,  6.2317e+01, -1.6204e+02,\n",
            "          4.2585e+01, -1.4745e+02,  6.6276e+00,  1.1535e+02,  2.6983e+02,\n",
            "         -1.0571e+02, -1.3242e+02,  1.8694e+02,  2.4293e+01, -1.1616e+02,\n",
            "         -5.8725e+00, -5.8352e+01,  1.5112e+02, -1.5598e+01, -7.5109e-01,\n",
            "          4.3431e+01,  2.3533e+01,  4.4708e+01, -2.9257e+01, -1.3207e+02,\n",
            "          4.4299e+01, -6.2105e+01, -1.8426e+00,  7.0903e+01,  2.4398e+02,\n",
            "         -5.6360e+01, -9.3901e+01, -4.7985e-02, -4.5765e+01,  1.6682e+02,\n",
            "          2.7101e+02,  9.5852e+01,  2.1011e+02,  1.9956e+02,  1.5586e+02,\n",
            "         -6.3348e+01,  1.4478e+02, -8.0097e+01,  1.5340e+02, -5.0399e+01,\n",
            "          1.9026e+01,  1.9679e+02,  1.8289e+02,  3.3356e+01,  4.1905e+01,\n",
            "          4.5282e+01, -5.0354e+01,  1.0324e+02, -2.6347e+01,  1.5366e+02,\n",
            "          2.2691e+01, -1.0336e+02, -1.2271e+02,  4.1978e+01,  1.2619e+02,\n",
            "          5.4702e+01, -2.8336e+01, -1.7420e+01, -6.0487e+01,  9.6979e+01,\n",
            "          1.9382e+02, -3.4635e+00, -2.5022e+01, -1.3297e+02,  3.9472e+01,\n",
            "         -5.5193e+01, -1.0057e+02,  2.7738e+01,  1.1329e+02,  5.8213e+01,\n",
            "          6.1148e+01, -2.0694e+01, -3.3461e+01,  5.9730e+01, -8.5295e+01,\n",
            "         -1.2230e+02,  1.4364e+01,  1.2352e+02, -2.4326e+01, -3.4575e+01,\n",
            "         -6.6090e+01,  7.9060e+01,  7.2648e+01,  1.5713e+02,  1.5374e+02,\n",
            "         -7.6797e+00,  1.6286e+02,  2.3705e+01, -4.1043e+01, -1.5955e+02,\n",
            "          2.7422e+01,  5.9698e+01, -1.0676e+02, -1.6797e+02,  9.2230e+01,\n",
            "          1.1976e+02, -1.5800e+02, -3.2616e+01,  1.3355e+02, -1.4806e+02,\n",
            "         -6.3251e+00, -3.3507e+01,  1.0867e+02,  8.3113e+01,  1.4297e+02,\n",
            "         -1.1922e+02,  6.5180e+01,  6.7116e+01,  2.3157e+01,  2.2618e+02,\n",
            "         -4.4951e+01,  7.1753e+00,  1.5124e+02, -7.9341e+01,  1.2062e+02,\n",
            "         -1.4419e+02, -1.2731e+02, -4.8746e+01,  9.8035e+01, -9.0264e+00,\n",
            "          1.0003e+02, -2.2823e+00, -1.6121e+02,  1.5187e+02,  6.3010e+01,\n",
            "          5.2602e+01, -5.0444e+01,  2.2859e+01,  1.0647e+01, -2.1622e+02,\n",
            "          1.5117e+01,  7.0071e+01,  6.5955e+01,  1.1879e+02,  1.5638e+02,\n",
            "          1.4451e+02,  4.4277e+00, -1.5742e+01, -6.7598e+01,  2.1808e+02,\n",
            "         -1.1767e+02,  1.4479e+02, -7.6297e+01,  1.6435e+01, -1.1581e+02,\n",
            "          1.1244e+02, -1.1829e+01,  4.4694e+01,  1.2993e+02,  8.5401e+01,\n",
            "          4.6081e+01,  1.5907e+02,  1.5962e+02, -2.2670e+02, -1.2393e+02,\n",
            "          7.5829e+01, -2.0906e+02, -3.5638e+00,  6.0132e+01, -1.4410e+02,\n",
            "         -5.0832e+01,  3.5845e+01, -1.3598e+02, -1.9678e+02, -5.3170e+01,\n",
            "          9.5093e+01,  4.0479e+01,  8.9716e+01,  1.8364e+02,  9.1123e+01,\n",
            "          1.1704e+02, -1.1502e+02,  1.6731e+01, -6.0417e+01, -9.0465e+01,\n",
            "         -8.2677e+01,  6.8221e+01,  4.4503e+01, -2.1259e+00,  5.0191e+01,\n",
            "         -3.1195e+01,  1.8217e+02, -1.4592e+02,  4.4462e+01, -3.6408e+01,\n",
            "         -3.6397e+01, -1.5874e+02,  9.7809e+01,  1.0880e+02,  1.7293e+01,\n",
            "         -1.2951e+01, -2.4717e+01, -7.0321e+01,  1.1403e+02, -2.0863e+01,\n",
            "         -2.0853e+02,  1.6902e+02,  4.6679e+01, -7.1145e+01,  1.0227e+02,\n",
            "         -5.4022e+01, -1.4553e+01, -8.5813e+01,  2.7147e+01, -1.2563e+02,\n",
            "          1.6508e+02,  1.0745e+02,  3.8310e+01, -6.7616e+01, -1.3578e+02,\n",
            "         -7.1705e+01, -6.1134e+01, -9.2050e+01, -3.6251e+01, -1.1415e+02,\n",
            "          9.2350e+01, -2.7317e+01, -5.6524e+01,  1.7832e+02,  8.8752e+01,\n",
            "         -9.6592e+00, -4.0293e+01,  2.5655e+02,  2.2544e+02, -1.3865e+02,\n",
            "         -8.4201e+01,  4.8765e+01,  3.6065e+01,  1.2698e+02, -3.8705e+01,\n",
            "         -1.2989e+02, -4.2052e+01, -7.5044e+01,  1.7766e+02, -1.3695e+02,\n",
            "          4.2249e+01, -1.0122e+01, -1.4650e+02, -2.0065e+02,  8.8113e+01,\n",
            "         -4.7725e+01, -9.5734e+01,  1.0166e+02,  1.5354e+02,  4.5476e+01,\n",
            "         -2.0038e+01,  5.5373e+01,  2.6165e+01,  1.8433e+02, -1.6853e+02,\n",
            "          1.6231e+02, -8.9871e+01, -5.8093e+01,  7.1300e+01, -4.3881e+01,\n",
            "          7.6828e+00,  2.3053e+00,  3.0562e+01, -9.2166e+01, -3.7057e+00,\n",
            "          1.5177e+00, -5.5960e+00, -4.7661e+01,  7.6784e+01,  1.4799e+02,\n",
            "         -1.4899e+01, -5.4907e+01, -5.7003e+01,  1.1136e+02,  1.3308e+01,\n",
            "         -2.1570e+01,  1.0498e+02, -5.4899e+01,  2.5437e+01, -3.0223e+01,\n",
            "          1.3570e+02,  1.8982e+02, -2.6237e+01, -6.2920e+01,  1.3729e+02,\n",
            "         -5.0882e+01,  7.4677e+01, -1.1964e+01, -1.0573e+02, -7.5807e+01,\n",
            "          5.8993e+01,  8.7703e+01, -1.1632e+02, -2.3537e+02,  1.2639e+02,\n",
            "          4.7484e+01,  6.3792e+01, -4.9908e+01,  1.7722e+02, -1.2207e+02,\n",
            "          1.3944e+02, -7.3802e+01,  8.9505e+01,  6.4511e+01,  7.6727e+01,\n",
            "          1.1257e+02, -2.5989e+01, -9.0570e+01,  1.0713e+02, -5.0715e+01,\n",
            "          5.3706e+01,  1.6562e+02,  6.3120e+01, -8.2058e+01,  5.7262e+00,\n",
            "         -1.2989e+02,  9.9472e+01,  4.2289e+01,  7.5766e+01,  4.1796e+01,\n",
            "          6.4123e+01, -3.0887e+02, -1.2526e+02, -7.1886e+01, -2.8778e+01,\n",
            "          4.8092e+01, -6.6028e+01,  1.9820e+02, -3.4671e+01, -3.4257e+01,\n",
            "          1.9143e+02,  3.2910e+02, -1.2765e+02,  1.3810e+02, -7.1261e+01,\n",
            "          4.3493e+01, -1.1765e+02, -6.8432e+01,  1.5691e+02, -3.4487e+01,\n",
            "          1.5281e+01,  2.0823e+02, -8.6309e+01,  6.0156e+01,  1.1991e+02,\n",
            "          8.8360e+01,  5.3158e+01,  8.3591e+01, -6.9376e+01,  5.7962e+01,\n",
            "         -5.5589e+01,  8.4460e+01,  3.6179e+01,  1.8101e+01,  1.7338e+02,\n",
            "          3.6578e+01, -3.3736e+01,  5.6912e+01, -1.4006e+02,  5.1430e+01,\n",
            "          2.9247e+02,  2.2191e+02, -1.0813e+02, -1.6894e+02,  8.4449e+01,\n",
            "          5.3840e+00,  5.4750e+01, -9.6588e+01,  1.7201e+02,  2.5833e+00,\n",
            "          2.5998e+01,  2.9863e+02,  4.0907e+01,  2.5111e+02,  2.2618e+01,\n",
            "         -9.3914e+01,  2.8798e+01, -6.9093e+01,  1.2106e+02,  8.0802e+01,\n",
            "          1.0390e+02,  1.5511e+02, -5.1595e+01,  3.1427e+01,  2.1721e+01,\n",
            "         -7.5728e+01,  9.1027e+01, -1.4604e+02,  2.7627e+02, -5.9000e+01,\n",
            "         -6.4335e+00, -8.0157e+01,  2.7193e+02,  1.6763e+01, -5.2932e+01,\n",
            "         -9.0880e+01,  1.8954e+01,  1.2663e+02,  1.5542e+02, -5.8107e+01,\n",
            "         -2.0323e+01,  1.6072e+02,  7.2266e+01,  1.8891e+02,  1.0823e+02,\n",
            "          4.6851e+01,  3.5514e+01, -9.8495e+01,  1.5883e+01, -4.1503e+01,\n",
            "         -6.7901e+01, -3.1433e+01,  1.1137e+02, -5.0069e+01,  8.2096e+01,\n",
            "         -1.4465e+02,  1.0243e+01,  1.7646e+02,  8.7272e+01,  1.4347e+02,\n",
            "          4.9377e+01, -1.1999e+02,  6.9279e+01, -6.6864e+01, -1.1636e+02,\n",
            "         -9.9389e+01,  1.2519e+02,  1.2850e+01,  4.4128e+01, -9.5727e+00,\n",
            "         -1.5920e+01,  3.0980e+01, -5.4603e+01, -8.2276e+01, -4.7036e+00,\n",
            "          2.1515e+02, -1.2622e+02, -9.8486e+01, -2.6686e+00,  1.1717e+02,\n",
            "          7.6515e+01, -8.6567e+01, -7.1718e+00, -1.8187e+01,  3.3767e+01,\n",
            "         -4.5311e+01, -1.1675e+02, -5.5091e+01, -7.5421e+01,  6.0090e+01,\n",
            "         -7.9926e+01, -6.2166e+01, -9.1924e+01,  8.0524e+01,  8.0969e+01,\n",
            "         -5.0558e+01,  2.2169e+01, -3.5397e+01, -9.2492e+00, -2.1398e+02,\n",
            "          2.4294e+01,  3.7152e+00, -1.3595e+02, -5.0120e+01, -1.9238e+01,\n",
            "         -7.9923e+01, -1.0734e+01, -3.0682e+01, -5.5093e+01, -3.7015e+01,\n",
            "          8.2484e+01, -6.4886e+01,  7.2546e+01, -1.8033e+00,  5.7850e+01,\n",
            "          8.3730e+00,  3.9055e+00, -1.2680e+02, -7.3240e+01, -1.8746e+02,\n",
            "         -2.1147e+02, -6.5171e+01, -9.9701e+00, -3.6674e+01, -6.0216e+01,\n",
            "         -3.9179e+00, -7.5100e+01, -6.3293e+01,  5.9201e+01, -3.6086e+01,\n",
            "         -3.5114e+01, -7.6808e+01,  9.5926e+01, -7.4706e+01, -1.7510e+02,\n",
            "          1.2538e+02, -1.7512e+02,  9.7096e+01, -9.0344e+01, -2.9578e+01,\n",
            "         -1.1028e+02, -2.0039e+02, -5.3599e+01, -4.8711e+01, -1.5490e+02,\n",
            "          4.5946e+01, -1.6130e+02, -2.5067e+01,  2.7110e+01, -1.0515e+02,\n",
            "         -2.1781e+01,  9.4367e+01, -9.4607e+01, -6.5526e+01, -7.1042e+01,\n",
            "          1.3934e+01, -4.4851e+01, -3.5728e+01,  4.8704e+01,  8.5035e+01]],\n",
            "       grad_fn=<AddmmBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOLbEMvy_L_O"
      },
      "source": [
        "\n",
        "\n",
        "fake_quant_model = Quant_Model(quat_min_model, torch.load('./weight_after_ps.pth'))\n",
        "fake_output = fake_quant_model(input_fp32)\n",
        "print(fake_output)"
      ],
      "id": "SOLbEMvy_L_O",
      "execution_count": null,
      "outputs": []
    }
  ]
}