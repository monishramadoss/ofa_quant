{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "ofa_quant.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monishramadoss/ofa_quant/blob/main/ofa_quant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BesMFL3fVdax",
        "outputId": "db14d017-2ecf-475a-8e80-add9424a7856"
      },
      "source": [
        "!pip install ofa\n",
        "!pip install torch==1.4.0 torchvision==0.5.0\n",
        "! git clone https://github.com/seshuad/IMagenet\n",
        "! ls 'IMagenet/tiny-imagenet-200/'"
      ],
      "id": "BesMFL3fVdax",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ofa in /usr/local/lib/python3.7/dist-packages (0.1.0.post202012082159)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from ofa) (1.4.0)\n",
            "Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: torchvision==0.5.0 in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0) (1.15.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0) (1.19.5)\n",
            "fatal: destination path 'IMagenet' already exists and is not an empty directory.\n",
            "test  train  val  wnids.txt  words.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp77tl4giVWJ"
      },
      "source": [
        "import time\n",
        "import skimage.io as nd\n",
        "import numpy as np\n",
        "\n",
        "path = 'IMagenet/tiny-imagenet-200/'\n",
        "\n",
        "def get_id_dictionary():\n",
        "    id_dict = {}\n",
        "    for i, line in enumerate(open( path + 'wnids.txt', 'r')):\n",
        "        id_dict[line.replace('\\n', '')] = i\n",
        "    return id_dict\n",
        "  \n",
        "def get_class_to_id_dict():\n",
        "    id_dict = get_id_dictionary()\n",
        "    all_classes = {}\n",
        "    result = {}\n",
        "    for i, line in enumerate(open( path + 'words.txt', 'r')):\n",
        "        n_id, word = line.split('\\t')[:2]\n",
        "        all_classes[n_id] = word\n",
        "    for key, value in id_dict.items():\n",
        "        result[value] = (key, all_classes[key])      \n",
        "    return result\n",
        "\n",
        "def get_data(id_dict):\n",
        "    print('starting loading data')\n",
        "    train_data, test_data = [], []\n",
        "    train_labels, test_labels = [], []\n",
        "    t = time.time()\n",
        "    for key, value in id_dict.items():\n",
        "        train_data += [nd.imread( path + 'train/{}/images/{}_{}.JPEG'.format(key, key, str(i)), ) for i in range(500)]\n",
        "        train_labels_ = np.array([[0]*200]*500)\n",
        "        train_labels_[:, value] = 1\n",
        "        train_labels += train_labels_.tolist()\n",
        "\n",
        "    for line in open( path + 'val/val_annotations.txt'):\n",
        "        img_name, class_id = line.split('\\t')[:2]\n",
        "        test_data = nd.imread( path + 'val/images/{}'.format(img_name))\n",
        "        test_data.append()\n",
        "        test_labels_ = np.array([[0]*200])\n",
        "        test_labels_[0, id_dict[class_id]] = 1\n",
        "        test_labels += test_labels_.tolist()\n",
        "\n",
        "    print('finished loading data, in {} seconds'.format(time.time() - t))\n",
        "    test = np.array(test_data), np.array(test_labels)  \n",
        "    return [np.array(train_data), np.array(train_labels), *test]\n",
        "\n",
        "# train_data, train_labels, test_data, test_labels = get_data(get_id_dictionary())"
      ],
      "id": "Kp77tl4giVWJ",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98SBhCpxVfeu",
        "outputId": "a9ae2b7e-a8cd-4129-f1a8-512233b82e3c"
      },
      "source": [
        "import copy\n",
        "import torch\n",
        "from ofa.model_zoo import ofa_net\n",
        "from ofa.imagenet_classification.data_providers.imagenet import ImagenetDataProvider\n",
        "from ofa.imagenet_classification.run_manager import ImagenetRunConfig, RunManager\n",
        "\n",
        "raw_resnet = ofa_net('ofa_resnet50', pretrained=True)\n",
        "raw_resnet.set_max_net()\n",
        "max_subnet = raw_resnet.get_active_subnet(preserve_weight=True)\n",
        "raw_resnet.set_active_subnet(d=0, w=0, e=0)\n",
        "min_subnet = raw_resnet.get_active_subnet(preserve_weight=True)\n",
        "\n",
        "\n",
        "ImagenetDataProvider.DEFAULT_PATH = path\n",
        "run_config = ImagenetRunConfig(test_batch_size=16, n_worker=20)\n",
        "run_config.data_provider.assign_active_img_size(224)\n",
        "\n",
        "\n",
        "run_manager = RunManager('./tmp/eval_subnet', min_subnet, run_config, init=False, )\n",
        "run_manager.reset_running_statistics(net=min_subnet)"
      ],
      "id": "98SBhCpxVfeu",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Color jitter: tf, resize_scale: 0.08, img_size: 224\n",
            "ResNets(\n",
            "  (input_stem): ModuleList(\n",
            "    (0): ConvLayer(\n",
            "      (conv): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "    )\n",
            "    (1): ConvLayer(\n",
            "      (conv): Conv2d(24, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (max_pooling): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (blocks): ModuleList(\n",
            "    (0): ResNetBottleneckBlock(\n",
            "      (conv1): Sequential(\n",
            "        (conv): Conv2d(40, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): Sequential(\n",
            "        (conv): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv3): Sequential(\n",
            "        (conv): Conv2d(8, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (downsample): Sequential(\n",
            "        (avg_pool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "        (conv): Conv2d(40, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (final_act): ReLU(inplace=True)\n",
            "    )\n",
            "    (1): ResNetBottleneckBlock(\n",
            "      (conv1): Sequential(\n",
            "        (conv): Conv2d(168, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): Sequential(\n",
            "        (conv): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv3): Sequential(\n",
            "        (conv): Conv2d(8, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (downsample): IdentityLayer()\n",
            "      (final_act): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): ResNetBottleneckBlock(\n",
            "      (conv1): Sequential(\n",
            "        (conv): Conv2d(168, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): Sequential(\n",
            "        (conv): Conv2d(8, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv3): Sequential(\n",
            "        (conv): Conv2d(8, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (downsample): Sequential(\n",
            "        (avg_pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "        (conv): Conv2d(168, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (final_act): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): ResNetBottleneckBlock(\n",
            "      (conv1): Sequential(\n",
            "        (conv): Conv2d(336, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): Sequential(\n",
            "        (conv): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv3): Sequential(\n",
            "        (conv): Conv2d(8, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (downsample): IdentityLayer()\n",
            "      (final_act): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): ResNetBottleneckBlock(\n",
            "      (conv1): Sequential(\n",
            "        (conv): Conv2d(336, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): Sequential(\n",
            "        (conv): Conv2d(8, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv3): Sequential(\n",
            "        (conv): Conv2d(8, 664, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (downsample): Sequential(\n",
            "        (avg_pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "        (conv): Conv2d(336, 664, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (final_act): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): ResNetBottleneckBlock(\n",
            "      (conv1): Sequential(\n",
            "        (conv): Conv2d(664, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): Sequential(\n",
            "        (conv): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv3): Sequential(\n",
            "        (conv): Conv2d(8, 664, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (downsample): IdentityLayer()\n",
            "      (final_act): ReLU(inplace=True)\n",
            "    )\n",
            "    (6): ResNetBottleneckBlock(\n",
            "      (conv1): Sequential(\n",
            "        (conv): Conv2d(664, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): Sequential(\n",
            "        (conv): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv3): Sequential(\n",
            "        (conv): Conv2d(8, 664, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (downsample): IdentityLayer()\n",
            "      (final_act): ReLU(inplace=True)\n",
            "    )\n",
            "    (7): ResNetBottleneckBlock(\n",
            "      (conv1): Sequential(\n",
            "        (conv): Conv2d(664, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): Sequential(\n",
            "        (conv): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv3): Sequential(\n",
            "        (conv): Conv2d(8, 664, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (downsample): IdentityLayer()\n",
            "      (final_act): ReLU(inplace=True)\n",
            "    )\n",
            "    (8): ResNetBottleneckBlock(\n",
            "      (conv1): Sequential(\n",
            "        (conv): Conv2d(664, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): Sequential(\n",
            "        (conv): Conv2d(8, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv3): Sequential(\n",
            "        (conv): Conv2d(8, 1328, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(1328, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (downsample): Sequential(\n",
            "        (avg_pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "        (conv): Conv2d(664, 1328, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(1328, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (final_act): ReLU(inplace=True)\n",
            "    )\n",
            "    (9): ResNetBottleneckBlock(\n",
            "      (conv1): Sequential(\n",
            "        (conv): Conv2d(1328, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): Sequential(\n",
            "        (conv): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (act): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv3): Sequential(\n",
            "        (conv): Conv2d(8, 1328, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(1328, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (downsample): IdentityLayer()\n",
            "      (final_act): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (global_avg_pool): MyGlobalAvgPool2d(keep_dim=False)\n",
            "  (classifier): LinearLayer(\n",
            "    (linear): Linear(in_features=1328, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n",
            "Total training params: 2.62M\n",
            "Total FLOPs: 311.31M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X2FmwwSqbGx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ece09d5-3cb7-4791-ed37-e287ababf0fa"
      },
      "source": [
        "loss, (top1, top5) = run_manager.validate(net=max_subnet)\n",
        "print('Results: loss=%.5f,\\t top1=%.1f,\\t top5=%.1f' % (loss, top1, top5))\n",
        "loss, (top1, top5) = run_manager.validate(net=min_subnet)\n",
        "print('Results: loss=%.5f,\\t top1=%.1f,\\t top5=%.1f' % (loss, top1, top5))"
      ],
      "id": "0X2FmwwSqbGx",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validate Epoch #1 : 100%|██████████| 625/625 [02:08<00:00,  4.86it/s, loss=8.46, top1=0.06, top5=0.42, img_size=224]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results: loss=8.45929,\t top1=0.1,\t top5=0.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validate Epoch #1 : 100%|██████████| 625/625 [00:37<00:00, 16.79it/s, loss=7.03, top1=0.01, top5=0.2, img_size=224]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results: loss=7.02851,\t top1=0.0,\t top5=0.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGw3VCBgash7"
      },
      "source": [
        "from ofa.imagenet_classification.networks import ResNets\n",
        "from ofa.utils.layers import IdentityLayer, ResidualBlock\n",
        "\n",
        "def val2list(val, repeat_time=1):\n",
        "    if isinstance(val, list) or isinstance(val, np.ndarray):\n",
        "        return val\n",
        "    elif isinstance(val, tuple):\n",
        "        return list(val)\n",
        "    else:\n",
        "        return [val for _ in range(repeat_time)]\n",
        "\n",
        "def set_active_subnet(ofa, d=None, e=None, w=None, **kwargs):\n",
        "    depth = val2list(d, len(ofa.BASE_DEPTH_LIST) + 1)\n",
        "    expand_ratio = val2list(e, len(ofa.blocks))\n",
        "    width_mult = val2list(w, len(ofa.BASE_DEPTH_LIST) + 2)\n",
        "    for block, e in zip(ofa.blocks, expand_ratio):\n",
        "        if e is not None:\n",
        "            block.active_expand_ratio = e\n",
        "\n",
        "    if width_mult[0] is not None:\n",
        "        ofa.input_stem[1].conv.active_out_channel = ofa.input_stem[0].active_out_channel = \\\n",
        "            ofa.input_stem[0].out_channel_list[width_mult[0]]\n",
        "    if width_mult[1] is not None:\n",
        "        ofa.input_stem[2].active_out_channel = ofa.input_stem[2].out_channel_list[width_mult[1]]\n",
        "\n",
        "    if depth[0] is not None:\n",
        "        ofa.input_stem_skipping = (depth[0] != max(ofa.depth_list))\n",
        "    for stage_id, (block_idx, d, w) in enumerate(zip(ofa.grouped_block_index, depth[1:], width_mult[2:])):\n",
        "        if d is not None:\n",
        "            ofa.runtime_depth[stage_id] = max(ofa.depth_list) - d\n",
        "        if w is not None:\n",
        "            for idx in block_idx:\n",
        "                ofa.blocks[idx].active_out_channel = ofa.blocks[idx].out_channel_list[w]\n",
        "\n",
        "def set_max_subnet(ofa):\n",
        "    set_active_subnet(ofa, max(ofa.depth_list), max(ofa.expand_ratio_list), len(ofa.width_mult_list) - 1)\n",
        "\n",
        "def get_active_subnet(ofa, preserve_weight=True):\n",
        "    input_stem = [ofa.input_stem[0].get_active_subnet(3, preserve_weight)]\n",
        "    active_out = ofa.input_stem[0].active_out_channel\n",
        "    input_stem_blocks = [0]\n",
        "\n",
        "    if ofa.input_stem_skipping <= 0:        \n",
        "        input_stem.append(ResidualBlock(\n",
        "            ofa.input_stem[1].conv.get_active_subnet(active_out, preserve_weight),\n",
        "            IdentityLayer(active_out, active_out)\n",
        "        ))\n",
        "        input_stem_blocks += [1]\n",
        "    input_stem_blocks += [2]\n",
        "    input_stem.append(ofa.input_stem[2].get_active_subnet(active_out, preserve_weight))\n",
        "    input_channel = ofa.input_stem[2].active_out_channel\n",
        "\n",
        "    blocks = []\n",
        "    block_groups = []\n",
        "    for stage_id, block_idx in enumerate(ofa.grouped_block_index):\n",
        "        depth_param = ofa.runtime_depth[stage_id]\n",
        "        active_idx = block_idx[:len(block_idx) - depth_param]\n",
        "        block_groups.append(active_idx)\n",
        "        for idx in active_idx:\n",
        "            blocks.append(ofa.blocks[idx].get_active_subnet(input_channel, preserve_weight))\n",
        "            input_channel = ofa.blocks[idx].active_out_channel\n",
        "    classifier = ofa.classifier.get_active_subnet(input_channel, preserve_weight)\n",
        "\n",
        "    subnet = ResNets(input_stem, blocks, classifier)\n",
        "    subnet.set_bn_param(**ofa.get_bn_param())\n",
        "    subnet.input_stem_blocks = input_stem_blocks\n",
        "    subnet.block_groups = block_groups\n",
        "    return subnet\n"
      ],
      "id": "mGw3VCBgash7",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjVCLHzLawE7"
      },
      "source": [
        "set_active_subnet(raw_resnet, 0, 0, 0)\n",
        "min_subnet = get_active_subnet(raw_resnet)\n",
        "\n",
        "set_max_subnet(raw_resnet)\n",
        "max_subnet = get_active_subnet(raw_resnet)\n",
        "\n",
        "max_subnet.eval()\n",
        "config = 'fbgemm'\n",
        "max_subnet.qconfig = torch.quantization.get_default_qconfig(config)\n",
        "max_subnet_1 = torch.quantization.prepare(max_subnet)\n",
        "quat_max_model = torch.quantization.convert(max_subnet_1).to('cuda:0')\n",
        "\n",
        "min_subnet.eval()\n",
        "min_subnet.qconfig = torch.quantization.get_default_qconfig(config)\n",
        "min_subnet_1 = torch.quantization.prepare(min_subnet)\n",
        "quat_min_model = torch.quantization.convert(min_subnet_1).to('cuda:0')\n"
      ],
      "id": "LjVCLHzLawE7",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JicLe9ftPPKO"
      },
      "source": [
        "loss, (top1, top5) = run_manager.validate(net=quat_max_model)\n",
        "print('Results: loss=%.5f,\\t top1=%.1f,\\t top5=%.1f' % (loss, top1, top5))\n",
        "loss, (top1, top5) = run_manager.validate(net=quat_min_model)\n",
        "print('Results: loss=%.5f,\\t top1=%.1f,\\t top5=%.1f' % (loss, top1, top5))"
      ],
      "id": "JicLe9ftPPKO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mi0n3pIBfbD9"
      },
      "source": [
        ""
      ],
      "id": "Mi0n3pIBfbD9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzk8k3BVflQl"
      },
      "source": [
        ""
      ],
      "id": "jzk8k3BVflQl",
      "execution_count": null,
      "outputs": []
    }
  ]
}